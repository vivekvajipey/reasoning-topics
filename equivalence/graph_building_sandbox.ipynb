{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token will not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\n",
      "Token is valid (permission: read).\n",
      "Your token has been saved to /scr/vvajipey/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f9f9a1990044900b4f86116952949c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "os.environ['HF_HOME'] = '/scr/vvajipey/.cache/huggingface'\n",
    "os.environ['HF_HUB'] = '/scr/vvajipey/.cache/huggingface'\n",
    "from huggingface_hub import login\n",
    "login(\"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\")\n",
    "\n",
    "import argparse\n",
    "import csv\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "import time\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, GenerationConfig\n",
    "\n",
    "gsm_df = pd.read_csv('../distribution/data/gsm8kTest.csv')\n",
    "\n",
    "model_name = \"mistralai/Mistral-7B-Instruct-v0.1\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = 'left'\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name, torch_dtype=torch.bfloat16, device_map=\"auto\")\n",
    "model.generation_config = GenerationConfig.from_pretrained(model_name)\n",
    "model.generation_config.pad_token_id = model.generation_config.eos_token_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get All Transitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "gsm_questions = gsm_df['question'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "q0 = gsm_questions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'reading_question': Counter({(\"Janet’s ducks lay 16 eggs per day. She eats three for breakfast every morning and bakes muffins for her friends every day with four. She sells the remainder at the farmers' market daily for $2 per fresh duck egg. How much in dollars does she make every day at the farmers' market?\",): 1})}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter, defaultdict\n",
    "all_equivalence_classes = {\"reading_question\": Counter([(q0,)])}\n",
    "all_equivalence_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['reading_question']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_equivalence_classes = list(all_equivalence_classes.keys())\n",
    "new_equivalence_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(set,\n",
       "            {'reading_question': {\"Janet’s ducks lay 16 eggs per day. She eats three for breakfast every morning and bakes muffins for her friends every day with four. She sells the remainder at the farmers' market daily for $2 per fresh duck egg. How much in dollars does she make every day at the farmers' market?\"}})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_wordings = defaultdict(set)\n",
    "unique_wordings[\"reading_question\"] = {q0}\n",
    "unique_wordings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['reading_question']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prev_equivalence_classes = new_equivalence_classes\n",
    "prev_equivalence_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'reading_question'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_name = prev_equivalence_classes[0]\n",
    "class_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({(\"Janet’s ducks lay 16 eggs per day. She eats three for breakfast every morning and bakes muffins for her friends every day with four. She sells the remainder at the farmers' market daily for $2 per fresh duck egg. How much in dollars does she make every day at the farmers' market?\",): 1})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_equivalence_classes[class_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def sample_paths(path_counter, n_samples):\n",
    "    \"\"\"\n",
    "    Sample from a path counter\n",
    "    \"\"\"\n",
    "    return random.choices(\n",
    "        list(path_counter.keys()), weights=list(path_counter.values()), k=n_samples\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(\"Janet’s ducks lay 16 eggs per day. She eats three for breakfast every morning and bakes muffins for her friends every day with four. She sells the remainder at the farmers' market daily for $2 per fresh duck egg. How much in dollars does she make every day at the farmers' market?\",),\n",
       " (\"Janet’s ducks lay 16 eggs per day. She eats three for breakfast every morning and bakes muffins for her friends every day with four. She sells the remainder at the farmers' market daily for $2 per fresh duck egg. How much in dollars does she make every day at the farmers' market?\",)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_samples = 2\n",
    "\n",
    "paths = sample_paths(all_equivalence_classes[class_name], n_samples)\n",
    "paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(\"Janet’s ducks lay 16 eggs per day. She eats three for breakfast every morning and bakes muffins for her friends every day with four. She sells the remainder at the farmers' market daily for $2 per fresh duck egg. How much in dollars does she make every day at the farmers' market?\",)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = paths[0]\n",
    "path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<model.sample>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROMPT:  Q: Janet’s ducks lay 16 eggs per day. She eats three for breakfast every morning and bakes muffins for her friends every day with four. She sells the remainder at the farmers' market daily for $2 per fresh duck egg. How much in dollars does she make every day at the farmers' market?\n",
      "A: Let's think step by step.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 91])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SAMPLING COMPLETION FROM MODEL\n",
    "# convert path to tokens, use stopping criteria etc. to generate new path\n",
    "from utils import get_prompt_message\n",
    "\n",
    "# NEED TO JOIN COMPONENTS IF COMPLETING PARTIAL TRACE...\n",
    "question_vector = tokenizer.apply_chat_template(get_prompt_message(path[0], 0), add_generation_prompt=True, return_tensors=\"pt\")\n",
    "input_tensor = question_vector.repeat(n_samples, 1)\n",
    "input_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prompt_with_step_splits_justin(question):\n",
    "    # get_prompt_message(overtime_question, 0)\n",
    "    fewshot_question = f\"\"\"ANSWER THE QUESTION STEP-BY-STEP AND CLEARLY MARK BETWEEN STEPS WITH <step split>.\n",
    "\n",
    "Q: Tina makes $18.00 an hour.  If she works more than 8 hours per shift, she is eligible for overtime, which is paid by your hourly wage + 1/2 your hourly wage.  If she works 10 hours every day for 5 days, how much money does she make?\n",
    "\n",
    "A:\n",
    "First, lets calculate how much Tina earns for working a regular 8-hour shift:\n",
    "Regular hours earned = Hourly wage * Hours worked per day * Number of days\n",
    "Regular hours earned = $18.00 * 8 * 5\n",
    "Regular hours earned = $720.00\n",
    "<step split>\n",
    "Next, lets calculate how many overtime hours she works in total:\n",
    "Overtime hours = Total hours worked - Regular hours\n",
    "Overtime hours = 10 hours * 5 days - 8 hours * 5 days\n",
    "Overtime hours = 10 * 5 - 8 * 5 Overtime hours = 50 hours - 40 hours\n",
    "Overtime hours = 10 hours\n",
    "<step split>\n",
    "Now, lets calculate the overtime pay for those 10 hours:\n",
    "Overtime pay per hour = Hourly wage + 1/2 hourly wage\n",
    "Overtime pay per hour = $18.00 + $9.00\n",
    "Overtime pay per hour = $27.00\n",
    "Total overtime pay = Overtime pay per hour * Overtime hours\n",
    "Total overtime pay = $27.00 * 10\n",
    "Total overtime pay = $270.00\n",
    "<step split>\n",
    "Finally, lets calculate her total earnings:\n",
    "Total earnings = Regular hours earned + Total overtime pay\n",
    "Total earnings = $720.00 + $270.00\n",
    "Total earnings = $990.00\n",
    "<step split>\n",
    " So, Tina makes a total of $990.00 for working 10 hours every day for 5 days\n",
    "\n",
    "Q: Joy can read 8 pages of a book in 20 minutes. How many hours will it take her to read 120 pages?\\n\n",
    "\n",
    "A:\n",
    " First, lets determine how many pages Joy reads in one minute:\n",
    " Pages read per minute = Pages read per 20 minutes / 20 minutes\n",
    " = 8 pages / 20 minutes = 0.4 pages per minute\n",
    "<step split>\n",
    " Next, well find out how long it takes Joy to read 120 pages:\n",
    " Time = Pages to be read / Pages read per minute\n",
    " = 120 pages / 0.4 pages per minute\n",
    " = 300 minutes\n",
    "<step split>\n",
    " Finally, well convert 300 minutes into hours:\n",
    " Hours = Minutes / 60\n",
    " = 300 minutes / 60\n",
    " = 5 hours\n",
    "<step split>\n",
    " So it will take Joy 5 hours to read 120\n",
    "\n",
    "Q: {question}\n",
    "\n",
    "A:\n",
    "\"\"\"\n",
    "    return [{\"role\": \"user\", \"content\": fewshot_question}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prompt_with_step_splits_ben(question):\n",
    "    # get_prompt_message(overtime_question, 0)\n",
    "    fewshot_question = f\"\"\"Q: Tina makes $18.00 an hour.  If she works more than 8 hours per shift, she is eligible for overtime, which is paid by your hourly wage + 1/2 your hourly wage.  If she works 10 hours every day for 5 days, how much money does she make?\n",
    "\n",
    "A:\n",
    "Step 1:\n",
    "First, lets calculate how much Tina earns for working a regular 8-hour shift:\n",
    "Regular hours earned = Hourly wage * Hours worked per day * Number of days\n",
    "Regular hours earned = $18.00 * 8 * 5\n",
    "Regular hours earned = $720.00\n",
    "Step 2:\n",
    "Next, lets calculate how many overtime hours she works in total:\n",
    "Overtime hours = Total hours worked - Regular hours\n",
    "Overtime hours = 10 hours * 5 days - 8 hours * 5 days\n",
    "Overtime hours = 10 * 5 - 8 * 5 Overtime hours = 50 hours - 40 hours\n",
    "Overtime hours = 10 hours\n",
    "Step 3:\n",
    "Now, lets calculate the overtime pay for those 10 hours:\n",
    "Overtime pay per hour = Hourly wage + 1/2 hourly wage\n",
    "Overtime pay per hour = $18.00 + $9.00\n",
    "Overtime pay per hour = $27.00\n",
    "Total overtime pay = Overtime pay per hour * Overtime hours\n",
    "Total overtime pay = $27.00 * 10\n",
    "Total overtime pay = $270.00\n",
    "Step 4:\n",
    "Finally, lets calculate her total earnings:\n",
    "Total earnings = Regular hours earned + Total overtime pay\n",
    "Total earnings = $720.00 + $270.00\n",
    "Total earnings = $990.00\n",
    "Step 5:\n",
    "So, Tina makes a total of $990.00 for working 10 hours every day for 5 days\n",
    "\n",
    "Q: Joy can read 8 pages of a book in 20 minutes. How many hours will it take her to read 120 pages?\\n\n",
    "\n",
    "A:\n",
    "Step 1: \n",
    " First, lets determine how many pages Joy reads in one minute:\n",
    " Pages read per minute = Pages read per 20 minutes / 20 minutes\n",
    " = 8 pages / 20 minutes = 0.4 pages per minute\n",
    "Step 2: \n",
    " Next, well find out how long it takes Joy to read 120 pages:\n",
    " Time = Pages to be read / Pages read per minute\n",
    " = 120 pages / 0.4 pages per minute\n",
    " = 300 minutes\n",
    "Step 3: \n",
    " Finally, well convert 300 minutes into hours:\n",
    " Hours = Minutes / 60\n",
    " = 300 minutes / 60\n",
    " = 5 hours\n",
    "Step 4: \n",
    " So it will take Joy 5 hours to read 120\n",
    "\n",
    "Q: {question}\n",
    "\n",
    "A:\n",
    "Step 1:\n",
    "\"\"\"\n",
    "    return [{\"role\": \"user\", \"content\": fewshot_question}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 767])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SAMPLING COMPLETION FROM MODEL\n",
    "# convert path to tokens, use stopping criteria etc. to generate new path\n",
    "\n",
    "# NEED TO JOIN COMPONENTS IF COMPLETING PARTIAL TRACE...\n",
    "n_samples = 1\n",
    "question_vector = tokenizer.apply_chat_template(prompt_with_step_splits_ben(path[0]), add_generation_prompt=True, return_tensors=\"pt\")\n",
    "input_tensor = question_vector.repeat(n_samples, 1)\n",
    "input_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop token IDs: [[7268, 28705, 28750, 28747], [7268, 28705, 28770, 28747]] ['Step 2:', 'Step 3:']\n"
     ]
    }
   ],
   "source": [
    "# from transformers import StoppingCriteria, StoppingCriteriaList\n",
    "\n",
    "# class BatchSentenceStoppingCriteria(StoppingCriteria):\n",
    "#     def __init__(self, tokenizer, stop_sequences=None):\n",
    "#         # Encode each stop sequence and store their token IDs\n",
    "#         # self.stop_token_ids = [[842, 28705], [13]]\n",
    "#         self.stop_token_ids = [[7268, 28705, 28750, 28747], [7268, 28705, 28770, 28747]]\n",
    "#         if stop_sequences:\n",
    "#             self.stop_token_ids = [tokenizer.encode(seq, add_special_tokens=False) for seq in stop_sequences]\n",
    "#         print(\"Stop token IDs:\", self.stop_token_ids, tokenizer.batch_decode(self.stop_token_ids))\n",
    "\n",
    "#     def __call__(self, input_ids: torch.LongTensor, scores: torch.FloatTensor, **kwargs) -> bool:\n",
    "#         # Initialize a tensor to keep track of which sequences should stop\n",
    "#         stop_mask = torch.zeros(input_ids.shape[0], dtype=torch.bool, device=input_ids.device)\n",
    "        \n",
    "#         # Check each stop sequence against the end of the input_ids for each sequence in the batch\n",
    "#         for stop_ids in self.stop_token_ids:\n",
    "#             if input_ids.shape[1] >= len(stop_ids):  # Ensure input_ids is long enough\n",
    "#                 # Check if the last tokens of input_ids match the stop sequence\n",
    "#                 match = torch.eq(input_ids[:, -len(stop_ids):], torch.tensor(stop_ids, device=input_ids.device)).all(dim=1)\n",
    "#                 stop_mask |= match  # Update the stop mask\n",
    "#                 if match.sum() > 0:                    \n",
    "#                     print(f\"Mask for {stop_ids}: \", stop_mask)\n",
    "        \n",
    "#         return stop_mask.any()\n",
    "\n",
    "# sentence_sampling_criteria = StoppingCriteriaList([BatchSentenceStoppingCriteria(tokenizer)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[28705, 13, 9977, 28705, 28781, 28747]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode(\"\\nStep 4:\", add_special_tokens=False)#, tokenizer.decode(28705)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0:  [13, 9977, 28705, 28734, 28747]\n",
      "Step 1:  [13, 9977, 28705, 28740, 28747]\n",
      "Step 2:  [13, 9977, 28705, 28750, 28747]\n",
      "Step 3:  [13, 9977, 28705, 28770, 28747]\n",
      "Step 4:  [13, 9977, 28705, 28781, 28747]\n",
      "Step 5:  [13, 9977, 28705, 28782, 28747]\n",
      "Step 6:  [13, 9977, 28705, 28784, 28747]\n",
      "Step 7:  [13, 9977, 28705, 28787, 28747]\n",
      "Step 8:  [13, 9977, 28705, 28783, 28747]\n",
      "Step 9:  [13, 9977, 28705, 28774, 28747]\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(f\"Step {i}: \", tokenizer.encode(f\"\\nStep {i}:\", add_special_tokens=False)[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop token IDs: [13, 9977, 28705, 28770, 28747]\n"
     ]
    }
   ],
   "source": [
    "# # # Working version with one stop seq\n",
    "\n",
    "from transformers import StoppingCriteria, StoppingCriteriaList\n",
    "# [[28789, 7691, 7925, 28767]]  # Tokens for <step split>\n",
    "class BatchSentenceStoppingCriteria(StoppingCriteria):\n",
    "    def __init__(self, tokenizer, stop_sequence=\"\\nStep 3:\"):\n",
    "        # Tokenize the stop sequence and store its token IDs\n",
    "        self.stop_token_ids = tokenizer.encode(stop_sequence, add_special_tokens=False)[1:]\n",
    "        # self.stop_token_ids = [9977, 28705, 28750, 28747]\n",
    "        print(\"Stop token IDs:\", self.stop_token_ids)  # Debugging to see the token IDs\n",
    "\n",
    "    def __call__(self, input_ids: torch.LongTensor, scores: torch.FloatTensor, **kwargs) -> bool:\n",
    "        # Check if the last tokens of input_ids match the stop sequence\n",
    "        if input_ids.shape[1] >= len(self.stop_token_ids):\n",
    "            # Extract the last tokens of the same length as the stop sequence\n",
    "            last_tokens = input_ids[:, -len(self.stop_token_ids):]\n",
    "            # Check if they match the stop sequence tokens\n",
    "            is_match = (last_tokens == torch.tensor(self.stop_token_ids, device=input_ids.device)).all(dim=1)\n",
    "            # If any sequence in the batch matches, return True to stop generation\n",
    "            if is_match.any():\n",
    "                print(\"Stopping sequence detected, stopping generation.\")\n",
    "                return True\n",
    "        return False\n",
    "\n",
    "sentence_sampling_criteria = StoppingCriteriaList([BatchSentenceStoppingCriteria(tokenizer)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop token IDs: [[13, 9977, 28705, 28734, 28747], [13, 9977, 28705, 28740, 28747], [13, 9977, 28705, 28750, 28747], [13, 9977, 28705, 28770, 28747], [13, 9977, 28705, 28781, 28747], [13, 9977, 28705, 28782, 28747], [13, 9977, 28705, 28784, 28747], [13, 9977, 28705, 28787, 28747], [13, 9977, 28705, 28783, 28747], [13, 9977, 28705, 28774, 28747]]\n",
      "Test Case 1:\n",
      "Generated Text: <s> Example text that does not end with the stopping sequence.\n",
      "\n",
      "This is an example sentence that does not end with the stopping sequence \".\". It continues on with additional information.</s> \n",
      "\n",
      "Test Case 2:\n",
      "Stopping sequence detected, stopping generation.\n",
      "Generated Text: <s> Please continue the pattern: \n",
      "Step 0: 0 \n",
      "Step 1: 1 \n",
      "Step 2: \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import StoppingCriteria, StoppingCriteriaList\n",
    "import torch\n",
    "\n",
    "class BatchSentenceStoppingCriteria(StoppingCriteria):\n",
    "    def __init__(self, tokenizer, stop_sequences):\n",
    "        # Tokenize each stop sequence and store their token IDs\n",
    "        self.stop_token_ids_list = [tokenizer.encode(seq, add_special_tokens=False)[1:] for seq in stop_sequences]\n",
    "        # self.stop_token_ids_list = [[9977, 28705, 28750, 28747], [9977, 28705, 28770, 28747], [9977, 28705, 28770, 28747]]\n",
    "        # self.stop_token_ids_list = [[9977, 28705, 28770, 28747], [9977, 28705, 28781, 28747]]\n",
    "        # self.stop_token_ids_list = [[9977, 28705, 28781, 28747], [9977, 28705, 28782, 28747]]\n",
    "        print(\"Stop token IDs:\", self.stop_token_ids_list)  # Debugging to see the token IDs\n",
    "\n",
    "    def __call__(self, input_ids: torch.LongTensor, scores: torch.FloatTensor, **kwargs) -> bool:\n",
    "        # Check each stop sequence against the end of the input_ids for each sequence in the batch\n",
    "        for stop_token_ids in self.stop_token_ids_list:\n",
    "            if input_ids.shape[1] >= len(stop_token_ids):\n",
    "                # Extract the last tokens of the same length as the stop sequence\n",
    "                last_tokens = input_ids[:, -len(stop_token_ids):]\n",
    "                # Check if they match the stop sequence tokens\n",
    "                is_match = (last_tokens == torch.tensor(stop_token_ids, device=input_ids.device)).all(dim=1)\n",
    "                # If any sequence in the batch matches, return True to stop generation\n",
    "                if is_match.any():\n",
    "                    print(\"Stopping sequence detected, stopping generation.\")\n",
    "                    return True\n",
    "        return False\n",
    "\n",
    "# Define multiple stop sequences\n",
    "stop_sequences = [f\"\\nStep {i}:\" for i in range(10)]\n",
    "stop_sequences.extend\n",
    "\n",
    "# Create stopping criteria\n",
    "stopping_criteria = StoppingCriteriaList([BatchSentenceStoppingCriteria(tokenizer, stop_sequences)])\n",
    "\n",
    "# Test inputs\n",
    "test_inputs = [\n",
    "    \"Example text that does not end with the stopping sequence.\",\n",
    "    \"Please continue the pattern: \\nStep 0: 0 \\nStep 1: 1\"\n",
    "]\n",
    "\n",
    "input_ids = [tokenizer.encode(ti, return_tensors=\"pt\") for ti in test_inputs]\n",
    "\n",
    "for i, ids in enumerate(input_ids):\n",
    "    print(f\"Test Case {i+1}:\")\n",
    "    outputs = model.generate(\n",
    "        ids.to(model.device), \n",
    "        max_length=50, \n",
    "        stopping_criteria=stopping_criteria\n",
    "    )\n",
    "    print(\"Generated Text:\", tokenizer.decode(outputs[0]), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping sequence detected, stopping generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 898])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs = model.generate(\n",
    "            input_tensor.to(model.device),\n",
    "            # min_new_tokens=min_new_tokens,\n",
    "            max_new_tokens=1000,\n",
    "            return_dict_in_generate=True,\n",
    "            output_scores=True,\n",
    "            do_sample=True,\n",
    "            temperature=0.7,\n",
    "            top_k=40,\n",
    "            stopping_criteria=sentence_sampling_criteria\n",
    "        )\n",
    "outputs.sequences.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"\\nStep 1:\\n [/INST] First, let's calculate how many eggs Janet has left after eating three for breakfast and giving four to her friends:\\n\\nEggs remaining = Eggs laid per day - Eggs eaten for breakfast - Eggs given to friends\\nEggs remaining = 16 eggs - 3 eggs - 4 eggs\\nEggs remaining = 9 eggs\\n\\nStep 2:\\nNext, let's calculate how many eggs Janet sells at the farmers' market:\\n\\nEggs sold = Eggs remaining\\nEggs sold = 9 eggs\\n\\nStep 3:\"]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.batch_decode(outputs.sequences[:, input_tensor.shape[1]-10:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id:  4205  -- tok:  First\n",
      "id:  28725  -- tok:  ,\n",
      "id:  1346  -- tok:  let\n",
      "id:  28742  -- tok:  '\n",
      "id:  28713  -- tok:  s\n",
      "id:  13911  -- tok:  calculate\n",
      "id:  272  -- tok:  the\n",
      "id:  1474  -- tok:  number\n",
      "id:  302  -- tok:  of\n",
      "id:  14636  -- tok:  eggs\n",
      "id:  2997  -- tok:  Jan\n",
      "id:  299  -- tok:  et\n",
      "id:  659  -- tok:  has\n",
      "id:  1749  -- tok:  left\n",
      "id:  1024  -- tok:  after\n",
      "id:  8652  -- tok:  eating\n",
      "id:  1712  -- tok:  three\n",
      "id:  354  -- tok:  for\n",
      "id:  11814  -- tok:  breakfast\n",
      "id:  304  -- tok:  and\n",
      "id:  5239  -- tok:  giving\n",
      "id:  2308  -- tok:  four\n",
      "id:  298  -- tok:  to\n",
      "id:  559  -- tok:  her\n",
      "id:  3282  -- tok:  friends\n",
      "id:  28747  -- tok:  :\n",
      "id:  13  -- tok:  \n",
      "\n",
      "id:  13  -- tok:  \n",
      "\n",
      "id:  28749  -- tok:  E\n",
      "id:  1576  -- tok:  gg\n",
      "id:  28713  -- tok:  s\n",
      "id:  1749  -- tok:  left\n",
      "id:  327  -- tok:  =\n",
      "id:  413  -- tok:  E\n",
      "id:  1576  -- tok:  gg\n",
      "id:  28713  -- tok:  s\n",
      "id:  10535  -- tok:  laid\n",
      "id:  387  -- tok:  -\n",
      "id:  413  -- tok:  E\n",
      "id:  6486  -- tok:  aten\n",
      "id:  354  -- tok:  for\n",
      "id:  11814  -- tok:  breakfast\n",
      "id:  387  -- tok:  -\n",
      "id:  12628  -- tok:  Given\n",
      "id:  298  -- tok:  to\n",
      "id:  3282  -- tok:  friends\n",
      "id:  13  -- tok:  \n",
      "\n",
      "id:  28749  -- tok:  E\n",
      "id:  1576  -- tok:  gg\n",
      "id:  28713  -- tok:  s\n",
      "id:  1749  -- tok:  left\n",
      "id:  327  -- tok:  =\n",
      "id:  28705  -- tok:  \n",
      "id:  28740  -- tok:  1\n",
      "id:  28784  -- tok:  6\n",
      "id:  387  -- tok:  -\n",
      "id:  28705  -- tok:  \n",
      "id:  28770  -- tok:  3\n",
      "id:  387  -- tok:  -\n",
      "id:  28705  -- tok:  \n",
      "id:  28781  -- tok:  4\n",
      "id:  13  -- tok:  \n",
      "\n",
      "id:  28749  -- tok:  E\n",
      "id:  1576  -- tok:  gg\n",
      "id:  28713  -- tok:  s\n",
      "id:  1749  -- tok:  left\n",
      "id:  327  -- tok:  =\n",
      "id:  28705  -- tok:  \n",
      "id:  28774  -- tok:  9\n",
      "id:  13  -- tok:  \n",
      "\n",
      "id:  13  -- tok:  \n",
      "\n",
      "id:  9977  -- tok:  Step\n",
      "id:  28705  -- tok:  \n",
      "id:  28750  -- tok:  2\n",
      "id:  28747  -- tok:  :\n"
     ]
    }
   ],
   "source": [
    "for id in outputs.sequences[0][input_tensor.shape[1]:]:\n",
    "    print(\"id: \", id.item(), \" -- tok: \", tokenizer.decode(id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def plot_tensor(tensor):\n",
    "    plt.imshow(tensor.cpu().numpy(), cmap='viridis')\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def convert_to_left_padded(tensor):\n",
    "    trimmed_sequences = []\n",
    "    for seq in tensor:\n",
    "        # Find indices of the first and last non-pad tokens\n",
    "        non_pad_indices = (seq != tokenizer.pad_token_id).nonzero(as_tuple=True)[0]\n",
    "        if len(non_pad_indices) > 0:\n",
    "            start_index = non_pad_indices[0]\n",
    "            end_index = non_pad_indices[-1] + 1\n",
    "            trimmed_sequences.append(seq[start_index:end_index])\n",
    "        else:\n",
    "            # if entire sequence is padding, use an empty sequence\n",
    "            trimmed_sequences.append(torch.tensor([], dtype=torch.long, device=model.device))\n",
    "\n",
    "    # Determine the maximum length after trimming\n",
    "    max_length = max(len(seq) for seq in trimmed_sequences)\n",
    "    padded_tensor = torch.full((tensor.shape[0], max_length), fill_value=tokenizer.pad_token_id, dtype=torch.long, device=model.device)\n",
    "\n",
    "    # put left padding\n",
    "    for i, seq in enumerate(trimmed_sequences):\n",
    "        padded_tensor[i, -len(seq):] = seq\n",
    "\n",
    "    return padded_tensor\n",
    "\n",
    "t2 = convert_to_left_padded(outputs.sequences)\n",
    "\n",
    "# from utils import plot_tensor\n",
    "plot_tensor(t2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[    1,   733, 16289, 28793,  1186, 28747,   320,  1380,  2870,   429,\n",
       "          28740, 28783, 28723, 28734, 28734,   396,  5115, 28723, 28705,  1047,\n",
       "            630,  3791,   680,   821, 28705, 28783,  3316,   660,  6139, 28725,\n",
       "            630,   349, 18711,   354,   754,  1536, 28725,   690,   349,  5907,\n",
       "            486,   574,  5115,   346, 21062,   648, 28705, 28740, 28748, 28750,\n",
       "            574,  5115,   346, 21062, 28723, 28705,  1047,   630,  3791, 28705,\n",
       "          28740, 28734,  3316,  1012,  1370,   354, 28705, 28782,  2202, 28725,\n",
       "            910,  1188,  2445,  1235,   630,  1038, 28804,    13,    13, 28741,\n",
       "          28747,    13,  9977, 28705, 28740, 28747,    13,  7489, 28725, 16143,\n",
       "          13911,   910,  1188,   320,  1380,  6384, 28713,   354,  2739,   264,\n",
       "           4392, 28705, 28783, 28733, 13785,  6139, 28747,    13,  2861,  1098,\n",
       "           3316, 12839,   327,   382,   423,   346, 21062,   398,   382,  2020,\n",
       "           4198,   660,  1370,   398,  8978,   302,  2202,    13,  2861,  1098,\n",
       "           3316, 12839,   327,   429, 28740, 28783, 28723, 28734, 28734,   398,\n",
       "          28705, 28783,   398, 28705, 28782,    13,  2861,  1098,  3316, 12839,\n",
       "            327,   429, 28787, 28750, 28734, 28723, 28734, 28734,    13,  9977,\n",
       "          28705, 28750, 28747,    13,  6693, 28725, 16143, 13911,   910,  1287,\n",
       "            754,  1536,  3316,   630,  3791,   297,  3102, 28747,    13,  2675,\n",
       "           1536,  3316,   327, 10711,  3316,  4198,   387, 28187,  3316,    13,\n",
       "           2675,  1536,  3316,   327, 28705, 28740, 28734,  3316,   398, 28705,\n",
       "          28782,  2202,   387, 28705, 28783,  3316,   398, 28705, 28782,  2202,\n",
       "             13,  2675,  1536,  3316,   327, 28705, 28740, 28734,   398, 28705,\n",
       "          28782,   387, 28705, 28783,   398, 28705, 28782,  5235,  1536,  3316,\n",
       "            327, 28705, 28782, 28734,  3316,   387, 28705, 28781, 28734,  3316,\n",
       "             13,  2675,  1536,  3316,   327, 28705, 28740, 28734,  3316,    13,\n",
       "           9977, 28705, 28770, 28747,    13,  8479, 28725, 16143, 13911,   272,\n",
       "            754,  1536,  2136,   354,  1395, 28705, 28740, 28734,  3316, 28747,\n",
       "             13,  2675,  1536,  2136,   660,  5115,   327,   382,   423,   346,\n",
       "          21062,   648, 28705, 28740, 28748, 28750,  5115,   346, 21062,    13,\n",
       "           2675,  1536,  2136,   660,  5115,   327,   429, 28740, 28783, 28723,\n",
       "          28734, 28734,   648,   429, 28774, 28723, 28734, 28734,    13,  2675,\n",
       "           1536,  2136,   660,  5115,   327,   429, 28750, 28787, 28723, 28734,\n",
       "          28734,    13, 10240,   754,  1536,  2136,   327,  5235,  1536,  2136,\n",
       "            660,  5115,   398,  5235,  1536,  3316,    13, 10240,   754,  1536,\n",
       "           2136,   327,   429, 28750, 28787, 28723, 28734, 28734,   398, 28705,\n",
       "          28740, 28734,    13, 10240,   754,  1536,  2136,   327,   429, 28750,\n",
       "          28787, 28734, 28723, 28734, 28734,    13,  9977, 28705, 28781, 28747,\n",
       "             13, 11491,   578, 28725, 16143, 13911,   559,  3102, 24431, 28747,\n",
       "             13, 10240, 24431,   327, 28187,  3316, 12839,   648, 10711,   754,\n",
       "           1536,  2136,    13, 10240, 24431,   327,   429, 28787, 28750, 28734,\n",
       "          28723, 28734, 28734,   648,   429, 28750, 28787, 28734, 28723, 28734,\n",
       "          28734,    13, 10240, 24431,   327,   429, 28774, 28774, 28734, 28723,\n",
       "          28734, 28734,    13,  9977, 28705, 28782, 28747,    13,  5142, 28725,\n",
       "            320,  1380,  2870,   264,  3102,   302,   429, 28774, 28774, 28734,\n",
       "          28723, 28734, 28734,   354,  2739, 28705, 28740, 28734,  3316,  1012,\n",
       "           1370,   354, 28705, 28782,  2202,    13,    13, 28824, 28747, 17780,\n",
       "            541,  1220, 28705, 28783,  6718,   302,   264,  1820,   297, 28705,\n",
       "          28750, 28734,  3486, 28723,  1602,  1287,  3316,   622,   378,  1388,\n",
       "            559,   298,  1220, 28705, 28740, 28750, 28734,  6718, 28804,    13,\n",
       "             13,    13, 28741, 28747,    13,  9977, 28705, 28740, 28747, 28705,\n",
       "             13,  4205, 28725, 16143,  7655,   910,  1287,  6718, 17780, 16336,\n",
       "            297,   624,  7117, 28747,    13,   367,  1291,  1220,   660,  7117,\n",
       "            327,   367,  1291,  1220,   660, 28705, 28750, 28734,  3486,   732,\n",
       "          28705, 28750, 28734,  3486,    13,   327, 28705, 28783,  6718,   732,\n",
       "          28705, 28750, 28734,  3486,   327, 28705, 28734, 28723, 28781,  6718,\n",
       "            660,  7117,    13,  9977, 28705, 28750, 28747, 28705,    13,  8580,\n",
       "          28725,  1162,  1300,   575,   910,  1043,   378,  4347, 17780,   298,\n",
       "           1220, 28705, 28740, 28750, 28734,  6718, 28747,    13,  5329,   327,\n",
       "            367,  1291,   298,   347,  1220,   732,   367,  1291,  1220,   660,\n",
       "           7117,    13,   327, 28705, 28740, 28750, 28734,  6718,   732, 28705,\n",
       "          28734, 28723, 28781,  6718,   660,  7117,    13,   327, 28705, 28770,\n",
       "          28734, 28734,  3486,    13,  9977, 28705, 28770, 28747, 28705,    13,\n",
       "           8126, 28725,  1162,  6603, 28705, 28770, 28734, 28734,  3486,   778,\n",
       "           3316, 28747,    13,   382,  2020,   327,  3197,  2907,   732, 28705,\n",
       "          28784, 28734,    13,   327, 28705, 28770, 28734, 28734,  3486,   732,\n",
       "          28705, 28784, 28734,    13,   327, 28705, 28782,  3316,    13,  9977,\n",
       "          28705, 28781, 28747, 28705,    13,  1537,   378,   622,  1388, 17780,\n",
       "          28705, 28782,  3316,   298,  1220, 28705, 28740, 28750, 28734,    13,\n",
       "             13, 28824, 28747,  2997,   299, 28809, 28713,   281, 18352,  4897,\n",
       "          28705, 28740, 28784, 14636,   660,  1370, 28723,   985,   317,  1449,\n",
       "           1712,   354, 11814,  1012,  3970,   304,   287,  1593,   290,  1292,\n",
       "           1126,   354,   559,  3282,  1012,  1370,   395,  2308, 28723,   985,\n",
       "           6112, 28713,   272, 23317,   438,   272, 17130, 28742,  2668,  6790,\n",
       "            354,   429, 28750,   660,  6138, 27103,  9119, 28723,  1602,  1188,\n",
       "            297,  9407,  1235,   630,  1038,  1012,  1370,   438,   272, 17130,\n",
       "          28742,  2668, 28804,    13,    13, 28741, 28747,    13,  9977, 28705,\n",
       "          28740, 28747,    13,   733, 28748, 16289, 28793,  4205, 28725,  1346,\n",
       "          28742, 28713, 13911,   910,  1287, 14636,  2997,   299,   659,  1749,\n",
       "           1024,  8652,  1712,   354, 11814,   304,  5239,  2308,   298,   559,\n",
       "           3282, 28747,    13,    13, 28749,  1576, 28713,  8409,   327,   413,\n",
       "           1576, 28713, 10535,   660,  1370,   387,   413,  1576, 28713, 21718,\n",
       "            354, 11814,   387,   413,  1576, 28713,  2078,   298,  3282,    13,\n",
       "          28749,  1576, 28713,  8409,   327, 28705, 28740, 28784, 14636,   387,\n",
       "          28705, 28770, 14636,   387, 28705, 28781, 14636,    13, 28749,  1576,\n",
       "          28713,  8409,   327, 28705, 28774, 14636,    13,    13,  9977, 28705,\n",
       "          28750, 28747,    13,  6693, 28725,  1346, 28742, 28713, 13911,   910,\n",
       "           1287, 14636,  2997,   299,  6112, 28713,   438,   272, 17130, 28742,\n",
       "           2668, 28747,    13,    13, 28749,  1576, 28713,  3910,   327,   413,\n",
       "           1576, 28713,  8409,    13, 28749,  1576, 28713,  3910,   327, 28705,\n",
       "          28774, 14636,    13,    13,  9977, 28705, 28770, 28747]],\n",
       "        device='cuda:0'),\n",
       " tensor([[    1,   733, 16289, 28793,  1186, 28747,   320,  1380,  2870,   429,\n",
       "          28740, 28783, 28723, 28734, 28734,   396,  5115, 28723, 28705,  1047,\n",
       "            630,  3791,   680,   821, 28705, 28783,  3316,   660,  6139, 28725,\n",
       "            630,   349, 18711,   354,   754,  1536, 28725,   690,   349,  5907,\n",
       "            486,   574,  5115,   346, 21062,   648, 28705, 28740, 28748, 28750,\n",
       "            574,  5115,   346, 21062, 28723, 28705,  1047,   630,  3791, 28705,\n",
       "          28740, 28734,  3316,  1012,  1370,   354, 28705, 28782,  2202, 28725,\n",
       "            910,  1188,  2445,  1235,   630,  1038, 28804,    13,    13, 28741,\n",
       "          28747,    13,  9977, 28705, 28740, 28747,    13,  7489, 28725, 16143,\n",
       "          13911,   910,  1188,   320,  1380,  6384, 28713,   354,  2739,   264,\n",
       "           4392, 28705, 28783, 28733, 13785,  6139, 28747,    13,  2861,  1098,\n",
       "           3316, 12839,   327,   382,   423,   346, 21062,   398,   382,  2020,\n",
       "           4198,   660,  1370,   398,  8978,   302,  2202,    13,  2861,  1098,\n",
       "           3316, 12839,   327,   429, 28740, 28783, 28723, 28734, 28734,   398,\n",
       "          28705, 28783,   398, 28705, 28782,    13,  2861,  1098,  3316, 12839,\n",
       "            327,   429, 28787, 28750, 28734, 28723, 28734, 28734,    13,  9977,\n",
       "          28705, 28750, 28747,    13,  6693, 28725, 16143, 13911,   910,  1287,\n",
       "            754,  1536,  3316,   630,  3791,   297,  3102, 28747,    13,  2675,\n",
       "           1536,  3316,   327, 10711,  3316,  4198,   387, 28187,  3316,    13,\n",
       "           2675,  1536,  3316,   327, 28705, 28740, 28734,  3316,   398, 28705,\n",
       "          28782,  2202,   387, 28705, 28783,  3316,   398, 28705, 28782,  2202,\n",
       "             13,  2675,  1536,  3316,   327, 28705, 28740, 28734,   398, 28705,\n",
       "          28782,   387, 28705, 28783,   398, 28705, 28782,  5235,  1536,  3316,\n",
       "            327, 28705, 28782, 28734,  3316,   387, 28705, 28781, 28734,  3316,\n",
       "             13,  2675,  1536,  3316,   327, 28705, 28740, 28734,  3316,    13,\n",
       "           9977, 28705, 28770, 28747,    13,  8479, 28725, 16143, 13911,   272,\n",
       "            754,  1536,  2136,   354,  1395, 28705, 28740, 28734,  3316, 28747,\n",
       "             13,  2675,  1536,  2136,   660,  5115,   327,   382,   423,   346,\n",
       "          21062,   648, 28705, 28740, 28748, 28750,  5115,   346, 21062,    13,\n",
       "           2675,  1536,  2136,   660,  5115,   327,   429, 28740, 28783, 28723,\n",
       "          28734, 28734,   648,   429, 28774, 28723, 28734, 28734,    13,  2675,\n",
       "           1536,  2136,   660,  5115,   327,   429, 28750, 28787, 28723, 28734,\n",
       "          28734,    13, 10240,   754,  1536,  2136,   327,  5235,  1536,  2136,\n",
       "            660,  5115,   398,  5235,  1536,  3316,    13, 10240,   754,  1536,\n",
       "           2136,   327,   429, 28750, 28787, 28723, 28734, 28734,   398, 28705,\n",
       "          28740, 28734,    13, 10240,   754,  1536,  2136,   327,   429, 28750,\n",
       "          28787, 28734, 28723, 28734, 28734,    13,  9977, 28705, 28781, 28747,\n",
       "             13, 11491,   578, 28725, 16143, 13911,   559,  3102, 24431, 28747,\n",
       "             13, 10240, 24431,   327, 28187,  3316, 12839,   648, 10711,   754,\n",
       "           1536,  2136,    13, 10240, 24431,   327,   429, 28787, 28750, 28734,\n",
       "          28723, 28734, 28734,   648,   429, 28750, 28787, 28734, 28723, 28734,\n",
       "          28734,    13, 10240, 24431,   327,   429, 28774, 28774, 28734, 28723,\n",
       "          28734, 28734,    13,  9977, 28705, 28782, 28747,    13,  5142, 28725,\n",
       "            320,  1380,  2870,   264,  3102,   302,   429, 28774, 28774, 28734,\n",
       "          28723, 28734, 28734,   354,  2739, 28705, 28740, 28734,  3316,  1012,\n",
       "           1370,   354, 28705, 28782,  2202,    13,    13, 28824, 28747, 17780,\n",
       "            541,  1220, 28705, 28783,  6718,   302,   264,  1820,   297, 28705,\n",
       "          28750, 28734,  3486, 28723,  1602,  1287,  3316,   622,   378,  1388,\n",
       "            559,   298,  1220, 28705, 28740, 28750, 28734,  6718, 28804,    13,\n",
       "             13,    13, 28741, 28747,    13,  9977, 28705, 28740, 28747, 28705,\n",
       "             13,  4205, 28725, 16143,  7655,   910,  1287,  6718, 17780, 16336,\n",
       "            297,   624,  7117, 28747,    13,   367,  1291,  1220,   660,  7117,\n",
       "            327,   367,  1291,  1220,   660, 28705, 28750, 28734,  3486,   732,\n",
       "          28705, 28750, 28734,  3486,    13,   327, 28705, 28783,  6718,   732,\n",
       "          28705, 28750, 28734,  3486,   327, 28705, 28734, 28723, 28781,  6718,\n",
       "            660,  7117,    13,  9977, 28705, 28750, 28747, 28705,    13,  8580,\n",
       "          28725,  1162,  1300,   575,   910,  1043,   378,  4347, 17780,   298,\n",
       "           1220, 28705, 28740, 28750, 28734,  6718, 28747,    13,  5329,   327,\n",
       "            367,  1291,   298,   347,  1220,   732,   367,  1291,  1220,   660,\n",
       "           7117,    13,   327, 28705, 28740, 28750, 28734,  6718,   732, 28705,\n",
       "          28734, 28723, 28781,  6718,   660,  7117,    13,   327, 28705, 28770,\n",
       "          28734, 28734,  3486,    13,  9977, 28705, 28770, 28747, 28705,    13,\n",
       "           8126, 28725,  1162,  6603, 28705, 28770, 28734, 28734,  3486,   778,\n",
       "           3316, 28747,    13,   382,  2020,   327,  3197,  2907,   732, 28705,\n",
       "          28784, 28734,    13,   327, 28705, 28770, 28734, 28734,  3486,   732,\n",
       "          28705, 28784, 28734,    13,   327, 28705, 28782,  3316,    13,  9977,\n",
       "          28705, 28781, 28747, 28705,    13,  1537,   378,   622,  1388, 17780,\n",
       "          28705, 28782,  3316,   298,  1220, 28705, 28740, 28750, 28734,    13,\n",
       "             13, 28824, 28747,  2997,   299, 28809, 28713,   281, 18352,  4897,\n",
       "          28705, 28740, 28784, 14636,   660,  1370, 28723,   985,   317,  1449,\n",
       "           1712,   354, 11814,  1012,  3970,   304,   287,  1593,   290,  1292,\n",
       "           1126,   354,   559,  3282,  1012,  1370,   395,  2308, 28723,   985,\n",
       "           6112, 28713,   272, 23317,   438,   272, 17130, 28742,  2668,  6790,\n",
       "            354,   429, 28750,   660,  6138, 27103,  9119, 28723,  1602,  1188,\n",
       "            297,  9407,  1235,   630,  1038,  1012,  1370,   438,   272, 17130,\n",
       "          28742,  2668, 28804,    13,    13, 28741, 28747,    13,  9977, 28705,\n",
       "          28740, 28747,    13,   733, 28748, 16289, 28793,  4205, 28725,  1346,\n",
       "          28742, 28713, 13911,   910,  1287, 14636,  2997,   299,   659,  1749,\n",
       "           1024,  8652,  1712,   354, 11814,   304,  5239,  2308,   298,   559,\n",
       "           3282, 28747,    13,    13, 28749,  1576, 28713,  8409,   327,   413,\n",
       "           1576, 28713, 10535,   660,  1370,   387,   413,  1576, 28713, 21718,\n",
       "            354, 11814,   387,   413,  1576, 28713,  2078,   298,  3282,    13,\n",
       "          28749,  1576, 28713,  8409,   327, 28705, 28740, 28784, 14636,   387,\n",
       "          28705, 28770, 14636,   387, 28705, 28781, 14636,    13, 28749,  1576,\n",
       "          28713,  8409,   327, 28705, 28774, 14636,    13,    13,  9977, 28705,\n",
       "          28750, 28747,    13,  6693, 28725,  1346, 28742, 28713, 13911,   910,\n",
       "           1287, 14636,  2997,   299,  6112, 28713,   438,   272, 17130, 28742,\n",
       "           2668, 28747,    13,    13, 28749,  1576, 28713,  3910,   327,   413,\n",
       "           1576, 28713,  8409,    13, 28749,  1576, 28713,  3910,   327, 28705,\n",
       "          28774, 14636,    13,    13,  9977, 28705, 28770, 28747]],\n",
       "        device='cuda:0'))"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t, t2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop token IDs: [[13, 9977, 28705, 28734, 28747], [13, 9977, 28705, 28740, 28747], [13, 9977, 28705, 28750, 28747], [13, 9977, 28705, 28770, 28747], [13, 9977, 28705, 28781, 28747], [13, 9977, 28705, 28782, 28747], [13, 9977, 28705, 28784, 28747], [13, 9977, 28705, 28787, 28747], [13, 9977, 28705, 28783, 28747], [13, 9977, 28705, 28774, 28747]]\n"
     ]
    }
   ],
   "source": [
    "class BatchSentenceStoppingCriteria(StoppingCriteria):\n",
    "    def __init__(self, tokenizer, stop_sequences):\n",
    "        # Tokenize each stop sequence and store their token IDs\n",
    "        self.stop_token_ids_list = [tokenizer.encode(seq, add_special_tokens=False)[1:] for seq in stop_sequences]\n",
    "        # self.stop_token_ids_list = [[9977, 28705, 28750, 28747], [9977, 28705, 28770, 28747], [9977, 28705, 28770, 28747]]\n",
    "        # self.stop_token_ids_list = [[9977, 28705, 28770, 28747], [9977, 28705, 28781, 28747]]\n",
    "        # self.stop_token_ids_list = [[9977, 28705, 28781, 28747], [9977, 28705, 28782, 28747]]\n",
    "        print(\"Stop token IDs:\", self.stop_token_ids_list)  # Debugging to see the token IDs\n",
    "\n",
    "    def __call__(self, input_ids: torch.LongTensor, scores: torch.FloatTensor, **kwargs) -> bool:\n",
    "        # Check each stop sequence against the end of the input_ids for each sequence in the batch\n",
    "        for stop_token_ids in self.stop_token_ids_list:\n",
    "            if input_ids.shape[1] >= len(stop_token_ids):\n",
    "                # Extract the last tokens of the same length as the stop sequence\n",
    "                last_tokens = input_ids[:, -len(stop_token_ids):]\n",
    "                # Check if they match the stop sequence tokens\n",
    "                is_match = (last_tokens == torch.tensor(stop_token_ids, device=input_ids.device)).all(dim=1)\n",
    "                # If any sequence in the batch matches, return True to stop generation\n",
    "                if is_match.any():\n",
    "                    print(\"Stopping sequence detected, stopping generation.\")\n",
    "                    return True\n",
    "        return False\n",
    "\n",
    "stop_sequences = [f\"\\nStep {i}:\" for i in range(10)]\n",
    "step_num_stopping_criteria = StoppingCriteriaList([BatchSentenceStoppingCriteria(tokenizer, stop_sequences)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode(\"</s>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ITERATION # 0\n",
      "Stopping sequence detected, stopping generation.\n",
      "[\"First, let's calculate how many eggs Janet has left after eating three for breakfast and baking muffins for her friends:\\n\\nEggs left = Eggs laid - Eggs eaten for breakfast - Eggs used for muffins\\nEggs left = 16 - 3 - 4\\nEggs left = 9\\n\\nStep 2:\"]\n",
      "ITERATION # 1\n",
      "Stopping sequence detected, stopping generation.\n",
      "[\"\\nNext, let's calculate how many eggs Janet sells at the farmers' market daily:\\n\\nEggs sold = Eggs left\\nEggs sold = 9\\n\\nStep 3:\"]\n",
      "ITERATION # 2\n",
      "Stopping sequence detected, stopping generation.\n",
      "[\"\\nNow, let's calculate the amount of money Janet makes from selling these eggs:\\n\\nMoney made = Eggs sold * Price per egg\\nMoney made = 9 * $2\\nMoney made = $18\\n\\nStep 4:\"]\n",
      "ITERATION # 3\n",
      "[\"\\nSo, Janet makes a total of $18 every day at the farmers' market.</s>\"]\n",
      "eos!\n"
     ]
    }
   ],
   "source": [
    "num_steps = 10\n",
    "\n",
    "cur_input = input_tensor\n",
    "\n",
    "for i in range(num_steps):\n",
    "        print(\"ITERATION #\", i)\n",
    "\n",
    "        outputs = model.generate(\n",
    "            cur_input.to(model.device),\n",
    "            min_new_tokens=10,\n",
    "            max_new_tokens=1000,\n",
    "            return_dict_in_generate=True,\n",
    "            output_scores=True,\n",
    "            do_sample=True,\n",
    "            temperature=0.7,\n",
    "            top_k=40,\n",
    "            stopping_criteria=step_num_stopping_criteria\n",
    "        )\n",
    "        # for id in outputs.sequences[0][cur_input.shape[1]:]:\n",
    "            # print(\"id: \", id.item(), \" -- tok: \", tokenizer.decode(id))\n",
    "\n",
    "        print(tokenizer.batch_decode(outputs.sequences[:, cur_input.shape[1]:]))\n",
    "        if outputs.sequences[0, -1] == 2:\n",
    "            print(\"eos!\")\n",
    "            break \n",
    "        # cur_input = outputs.sequences\n",
    "        cur_input = convert_to_left_padded(outputs.sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping sequence detected, stopping generation.\n"
     ]
    }
   ],
   "source": [
    "gen_outputs = model.generate(\n",
    "            input_tensor.to(model.device),\n",
    "            min_new_tokens=10,\n",
    "            max_new_tokens=1000,\n",
    "            return_dict_in_generate=True,\n",
    "            output_scores=True,\n",
    "            do_sample=True,\n",
    "            temperature=0.7,\n",
    "            top_k=40,\n",
    "            stopping_criteria=step_num_stopping_criteria\n",
    "        ).sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"<s> [INST] Q: Tina makes $18.00 an hour.  If she works more than 8 hours per shift, she is eligible for overtime, which is paid by your hourly wage + 1/2 your hourly wage.  If she works 10 hours every day for 5 days, how much money does she make?\\n\\nA:\\nStep 1:\\nFirst, lets calculate how much Tina earns for working a regular 8-hour shift:\\nRegular hours earned = Hourly wage * Hours worked per day * Number of days\\nRegular hours earned = $18.00 * 8 * 5\\nRegular hours earned = $720.00\\nStep 2:\\nNext, lets calculate how many overtime hours she works in total:\\nOvertime hours = Total hours worked - Regular hours\\nOvertime hours = 10 hours * 5 days - 8 hours * 5 days\\nOvertime hours = 10 * 5 - 8 * 5 Overtime hours = 50 hours - 40 hours\\nOvertime hours = 10 hours\\nStep 3:\\nNow, lets calculate the overtime pay for those 10 hours:\\nOvertime pay per hour = Hourly wage + 1/2 hourly wage\\nOvertime pay per hour = $18.00 + $9.00\\nOvertime pay per hour = $27.00\\nTotal overtime pay = Overtime pay per hour * Overtime hours\\nTotal overtime pay = $27.00 * 10\\nTotal overtime pay = $270.00\\nStep 4:\\nFinally, lets calculate her total earnings:\\nTotal earnings = Regular hours earned + Total overtime pay\\nTotal earnings = $720.00 + $270.00\\nTotal earnings = $990.00\\nStep 5:\\nSo, Tina makes a total of $990.00 for working 10 hours every day for 5 days\\n\\nQ: Joy can read 8 pages of a book in 20 minutes. How many hours will it take her to read 120 pages?\\n\\n\\nA:\\nStep 1: \\n First, lets determine how many pages Joy reads in one minute:\\n Pages read per minute = Pages read per 20 minutes / 20 minutes\\n = 8 pages / 20 minutes = 0.4 pages per minute\\nStep 2: \\n Next, well find out how long it takes Joy to read 120 pages:\\n Time = Pages to be read / Pages read per minute\\n = 120 pages / 0.4 pages per minute\\n = 300 minutes\\nStep 3: \\n Finally, well convert 300 minutes into hours:\\n Hours = Minutes / 60\\n = 300 minutes / 60\\n = 5 hours\\nStep 4: \\n So it will take Joy 5 hours to read 120\\n\\nQ: Janet’s ducks lay 16 eggs per day. She eats three for breakfast every morning and bakes muffins for her friends every day with four. She sells the remainder at the farmers' market daily for $2 per fresh duck egg. How much in dollars does she make every day at the farmers' market?\\n\\nA:\\nStep 1:\\n [/INST] First, let's calculate how many eggs Janet has left after eating three for breakfast and giving four to her friends:\\n\\nRemaining eggs = Eggs laid per day - Eggs eaten for breakfast - Eggs used for muffins\\n= 16 - 3 - 4\\n= 9\\n\\nStep 2:\"]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.batch_decode(gen_outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "</model.sample>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nightly",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
