{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pytorch'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mast\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpytorch\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pytorch'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import ast\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = None\n",
    "pathname = \"/Users/adityatadimeti/reasoning-topics/conditional/data/\"\n",
    "for path in os.listdir(pathname):\n",
    "    if path.endswith(\".csv\"):\n",
    "        if df is None:\n",
    "            df = pd.read_csv(pathname + path)\n",
    "        else:\n",
    "            df = pd.concat([df, pd.read_csv(pathname + path)])\n",
    "\n",
    "# Keep unique rows\n",
    "df = df.drop_duplicates()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of questions 8\n"
     ]
    }
   ],
   "source": [
    "unique_questions = df[\"Question\"].unique()\n",
    "print(\"Number of questions\", len(unique_questions)) # Number of questions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_dfs = []\n",
    "for question in unique_questions:\n",
    "    question_dfs.append(df[df[\"Question\"] == question])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q0 unique step orders: 11 Q0 # generations 25\n",
      "Q1 unique step orders: 21 Q1 # generations 25\n",
      "Q2 unique step orders: 6 Q2 # generations 25\n",
      "Q3 unique step orders: 9 Q3 # generations 25\n",
      "Q4 unique step orders: 16 Q4 # generations 25\n",
      "Q5 unique step orders: 14 Q5 # generations 25\n",
      "Q6 unique step orders: 7 Q6 # generations 25\n",
      "Q7 unique step orders: 18 Q7 # generations 25\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for i in range(len(question_dfs)):\n",
    "    set_of_buckets = set()\n",
    "    for row in question_dfs[i].iterrows():\n",
    "        replaced_row = row[1][\"Merged buckets\"].replace(\"[\",\"\").replace(\"]\",\"\")\n",
    "        list_of_tuples = ast.literal_eval(f\"[{replaced_row}]\")\n",
    "        second_elems = [x[1] for x in list_of_tuples]\n",
    "        string_second_elems = \"\".join(second_elems)\n",
    "        set_of_buckets.add(string_second_elems)\n",
    "    print(f\"Q{i} unique step orders: {len(set_of_buckets)}\", f\"Q{i} # generations {len(question_dfs[1])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file_path in os.listdir(\"/Users/adityatadimeti/reasoning-topics/conditional/data/tensors/\"):\n",
    "    counter = 0\n",
    "    if \"CoT\" not in file_path:\n",
    "        continue\n",
    "    if counter == 8:\n",
    "        break\n",
    "\n",
    "    dir = \"/Users/adityatadimeti/reasoning-topics/conditional/data/tensors/\" + file_path\n",
    "    tensor = torch.load(dir, map_location=\"cpu\") # Load the file into a tensor\n",
    "    \n",
    "    counter += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "reasoning-research",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
