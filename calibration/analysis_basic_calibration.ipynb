{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['HF_HOME'] = '/scr/vvajipey/.cache/huggingface'\n",
    "os.environ['HF_HUB'] = '/scr/vvajipey/.cache/huggingface'\n",
    "from huggingface_hub import login\n",
    "login(\"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\")\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "from collections import Counter, defaultdict\n",
    "from difflib import get_close_matches\n",
    "from pprint import pprint\n",
    "import random\n",
    "import re\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, GenerationConfig\n",
    "from transformers import StoppingCriteria, StoppingCriteriaList\n",
    "import torch.nn.functional as F\n",
    "\n",
    "model_name = \"mistral-7b-v0.1\"\n",
    "\n",
    "name2base = {\"mistral-7b-v0.1\":\"mistralai/Mistral-7B-v0.1\"}\n",
    "name2instruct = {\"mistral-7b-v0.1\": \"mistralai/Mistral-7B-Instruct-v0.1\"}\n",
    "\n",
    "base_model_name = name2base[model_name]\n",
    "print(\"Loading \", base_model_name)\n",
    "base_tokenizer = AutoTokenizer.from_pretrained(base_model_name)\n",
    "base_tokenizer.pad_token = base_tokenizer.eos_token\n",
    "base_model = AutoModelForCausalLM.from_pretrained(base_model_name, torch_dtype=torch.bfloat16, device_map=\"auto\")\n",
    "base_model.generation_config = GenerationConfig.from_pretrained(base_model_name)\n",
    "base_model.generation_config.pad_token_id =base_model.generation_config.eos_token_id\n",
    "\n",
    "name2instruct = {\"mistral-7b-v0.1\": \"mistralai/Mistral-7B-Instruct-v0.1\"}\n",
    "instruct_model_name = name2instruct[model_name]\n",
    "instruct_tokenizer = AutoTokenizer.from_pretrained(instruct_model_name)\n",
    "instruct_tokenizer.pad_token = instruct_tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('logs/base_logprobs_commonsense_qa_train_q1_t0.7_tk40.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_paths_with_base_model(q_A_tensor, A_length, model, tokenizer):\n",
    "    q_A_tensor = q_A_tensor.to(model.device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(q_A_tensor)\n",
    "    \n",
    "    logprobs = torch.log_softmax(outputs.logits, dim=1).detach()\n",
    "    logprobs = logprobs[:, :-1, :]\n",
    "    q_A_tensor = q_A_tensor[:, 1:]\n",
    "\n",
    "    gen_logprobs = torch.gather(logprobs, 2, q_A_tensor[:, :, None]).squeeze(-1)\n",
    "    masked_logprobs = gen_logprobs\n",
    "    masked_logprobs[:, :-A_length] = 0\n",
    "    summed_logprobs = masked_logprobs.sum(dim=1)\n",
    "\n",
    "    # print_all_logprobs = False \n",
    "    print_all_logprobs = False\n",
    "    if print_all_logprobs:\n",
    "            print(\"summed_probs: \", summed_logprobs.shape)\n",
    "            for input_sentence, input_probs in zip(q_A_tensor , masked_logprobs):\n",
    "            # for input_sentence, input_probs in zip(s1_s2_tensor , gen_logprobs): # check all logprobs\n",
    "                for token, p in zip(input_sentence, input_probs):\n",
    "                    if token not in tokenizer.all_special_ids:\n",
    "                        print(f\"{tokenizer.decode(token)} ({token}): {p.item()}\")\n",
    "\n",
    "    return summed_logprobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare(letter, csqa_df, question_tok_len):\n",
    "    df_subset = df[df['answer_letter'] == letter]\n",
    "\n",
    "    total_summed_logprobs_tensor = torch.tensor(df_subset['total_summed_logprobs'].values, dtype=torch.float32)\n",
    "    logsumexp_result = torch.logsumexp(total_summed_logprobs_tensor, dim=0)\n",
    "\n",
    "    print(f\"LogSumExp of total_summed_logprobs for answer_letter '{letter}':\", logsumexp_result.item())\n",
    "\n",
    "    q_num = 1\n",
    "\n",
    "    prompt = f\"\"\"Question: {csqa_df['question'][q_num]}\n",
    "            Choices:\n",
    "            (A) {csqa_df['choices'][q_num]['text'][0]}\n",
    "            (B) {csqa_df['choices'][q_num]['text'][1]}\n",
    "            (C) {csqa_df['choices'][q_num]['text'][2]}\n",
    "            (D) {csqa_df['choices'][q_num]['text'][3]}\n",
    "            (E) {csqa_df['choices'][q_num]['text'][4]}\n",
    "            Answer:\"\"\"\n",
    "\n",
    "    chat = [{\"role\":\"user\", \"content\": prompt}]\n",
    "\n",
    "    answer_prefix = instruct_tokenizer.encode(\n",
    "        instruct_tokenizer.apply_chat_template(chat, tokenize=False) + f\" The answer is ({letter}).\", \n",
    "        return_tensors='pt', \n",
    "        add_special_tokens=False\n",
    "        )\n",
    "    \n",
    "    A_length = answer_prefix.shape[1] - question_tok_len \n",
    "\n",
    "    summed_logprobs = score_paths_with_base_model(answer_prefix, A_length, base_model, instruct_tokenizer)\n",
    "    print(f'P({letter}) = ', summed_logprobs)\n",
    "\n",
    "    return logsumexp_result, summed_logprobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sandbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question_number</th>\n",
       "      <th>answer_letter</th>\n",
       "      <th>total_summed_logprobs</th>\n",
       "      <th>norm_total_summed_logprobs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>-333.850586</td>\n",
       "      <td>-3.974412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>-384.563782</td>\n",
       "      <td>-4.578140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>-176.801666</td>\n",
       "      <td>-2.104782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>-454.278381</td>\n",
       "      <td>-5.408076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>-434.741730</td>\n",
       "      <td>-5.175497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>1</td>\n",
       "      <td>E</td>\n",
       "      <td>-973.090393</td>\n",
       "      <td>-5.657502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>1</td>\n",
       "      <td>E</td>\n",
       "      <td>-1433.389160</td>\n",
       "      <td>-8.333658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>1</td>\n",
       "      <td>E</td>\n",
       "      <td>-954.083435</td>\n",
       "      <td>-5.546997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>1</td>\n",
       "      <td>E</td>\n",
       "      <td>-1887.480469</td>\n",
       "      <td>-10.973723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>1</td>\n",
       "      <td>E</td>\n",
       "      <td>-1575.552734</td>\n",
       "      <td>-9.160191</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     question_number answer_letter  total_summed_logprobs  \\\n",
       "0                  1             A            -333.850586   \n",
       "1                  1             A            -384.563782   \n",
       "2                  1             A            -176.801666   \n",
       "3                  1             A            -454.278381   \n",
       "4                  1             A            -434.741730   \n",
       "..               ...           ...                    ...   \n",
       "495                1             E            -973.090393   \n",
       "496                1             E           -1433.389160   \n",
       "497                1             E            -954.083435   \n",
       "498                1             E           -1887.480469   \n",
       "499                1             E           -1575.552734   \n",
       "\n",
       "     norm_total_summed_logprobs  \n",
       "0                     -3.974412  \n",
       "1                     -4.578140  \n",
       "2                     -2.104782  \n",
       "3                     -5.408076  \n",
       "4                     -5.175497  \n",
       "..                          ...  \n",
       "495                   -5.657502  \n",
       "496                   -8.333658  \n",
       "497                   -5.546997  \n",
       "498                  -10.973723  \n",
       "499                   -9.160191  \n",
       "\n",
       "[500 rows x 4 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('logs/base_logprobs_commonsense_qa_train_q1_t0.7_tk40.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogSumExp of total_summed_logprobs for answer_letter 'A': -75.19791412353516\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "df_subset = df[df['answer_letter'] == 'A']\n",
    "\n",
    "total_summed_logprobs_tensor = torch.tensor(df_subset['total_summed_logprobs'].values, dtype=torch.float32)\n",
    "logsumexp_result = torch.logsumexp(total_summed_logprobs_tensor, dim=0)\n",
    "\n",
    "print(\"LogSumExp of total_summed_logprobs for answer_letter 'A':\", logsumexp_result.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token will not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\n",
      "Token is valid (permission: read).\n",
      "Your token has been saved to /scr/vvajipey/.cache/huggingface/token\n",
      "Login successful\n",
      "Loading  mistralai/Mistral-7B-v0.1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b86bc3d777e94832b42a508b77ca7aea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "os.environ['HF_HOME'] = '/scr/vvajipey/.cache/huggingface'\n",
    "os.environ['HF_HUB'] = '/scr/vvajipey/.cache/huggingface'\n",
    "from huggingface_hub import login\n",
    "login(\"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\")\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "from collections import Counter, defaultdict\n",
    "from difflib import get_close_matches\n",
    "from pprint import pprint\n",
    "import random\n",
    "import re\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, GenerationConfig\n",
    "from transformers import StoppingCriteria, StoppingCriteriaList\n",
    "import torch.nn.functional as F\n",
    "\n",
    "model_name = \"mistral-7b-v0.1\"\n",
    "\n",
    "name2base = {\"mistral-7b-v0.1\":\"mistralai/Mistral-7B-v0.1\"}\n",
    "name2instruct = {\"mistral-7b-v0.1\": \"mistralai/Mistral-7B-Instruct-v0.1\"}\n",
    "\n",
    "base_model_name = name2base[model_name]\n",
    "print(\"Loading \", base_model_name)\n",
    "base_tokenizer = AutoTokenizer.from_pretrained(base_model_name)\n",
    "base_tokenizer.pad_token = base_tokenizer.eos_token\n",
    "base_model = AutoModelForCausalLM.from_pretrained(base_model_name, torch_dtype=torch.bfloat16, device_map=\"auto\")\n",
    "base_model.generation_config = GenerationConfig.from_pretrained(base_model_name)\n",
    "base_model.generation_config.pad_token_id =base_model.generation_config.eos_token_id\n",
    "\n",
    "name2instruct = {\"mistral-7b-v0.1\": \"mistralai/Mistral-7B-Instruct-v0.1\"}\n",
    "instruct_model_name = name2instruct[model_name]\n",
    "instruct_tokenizer = AutoTokenizer.from_pretrained(instruct_model_name)\n",
    "instruct_tokenizer.pad_token = instruct_tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_num = 1\n",
    "answer_letter = 'A'\n",
    "\n",
    "import ast\n",
    "\n",
    "csqa_df = pd.read_csv('data/commonsense_qa_train.csv')\n",
    "csqa_df['choices'] = csqa_df['choices'].apply(ast.literal_eval)\n",
    "\n",
    "prompt = f\"\"\"Question: {csqa_df['question'][q_num]}\n",
    "        Choices:\n",
    "        (A) {csqa_df['choices'][q_num]['text'][0]}\n",
    "        (B) {csqa_df['choices'][q_num]['text'][1]}\n",
    "        (C) {csqa_df['choices'][q_num]['text'][2]}\n",
    "        (D) {csqa_df['choices'][q_num]['text'][3]}\n",
    "        (E) {csqa_df['choices'][q_num]['text'][4]}\n",
    "        Answer:\"\"\"\n",
    "\n",
    "chat = [{\"role\":\"user\", \"content\": prompt}]\n",
    "\n",
    "question_tensor = instruct_tokenizer.apply_chat_template(chat, return_tensors='pt', tokenize=True)\n",
    "\n",
    "answer_prefix = instruct_tokenizer.encode(\n",
    "    instruct_tokenizer.apply_chat_template(chat, tokenize=False) + f\" The answer is ({answer_letter}).\", \n",
    "    return_tensors='pt', \n",
    "    add_special_tokens=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 71])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 77])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer_prefix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "         1., 1.]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a binary mask of the last (answer_prefix.shape[1] - question_tensor.shape[1]) tokens of answer_prefix\n",
    "mask_length = answer_prefix.shape[1] - question_tensor.shape[1]\n",
    "binary_mask = torch.cat([torch.zeros(question_tensor.shape[1]), torch.ones(mask_length)]).unsqueeze(0)\n",
    "binary_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 75])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binary_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "summed_probs:  torch.Size([1])\n",
      "] (28793): -0.0\n",
      "Question (22478): -0.0\n",
      ": (28747): -0.0\n",
      "Sam (4157): -0.0\n",
      "my (1916): -0.0\n",
      "wanted (2613): -0.0\n",
      "to (298): -0.0\n",
      "go (576): -0.0\n",
      "to (298): -0.0\n",
      "where (970): -0.0\n",
      "the (272): -0.0\n",
      "people (905): -0.0\n",
      "were (654): -0.0\n",
      ". (28723): -0.0\n",
      " (28705): -0.0\n",
      "Where (6926): -0.0\n",
      "might (1659): -0.0\n",
      "he (400): -0.0\n",
      "go (576): -0.0\n",
      "? (28804): -0.0\n",
      "\n",
      " (13): -0.0\n",
      "       (5390): -0.0\n",
      "Cho (25405): -0.0\n",
      "ices (1214): -0.0\n",
      ": (28747): -0.0\n",
      "\n",
      " (13): -0.0\n",
      "       (5390): -0.0\n",
      "( (325): -0.0\n",
      "A (28741): -0.0\n",
      ") (28731): -0.0\n",
      "race (5941): -0.0\n",
      "track (3508): -0.0\n",
      "\n",
      " (13): -0.0\n",
      "       (5390): -0.0\n",
      "( (325): -0.0\n",
      "B (28760): -0.0\n",
      ") (28731): -0.0\n",
      "pop (1852): -0.0\n",
      "ulated (6432): -0.0\n",
      "areas (5020): -0.0\n",
      "\n",
      " (13): -0.0\n",
      "       (5390): -0.0\n",
      "( (325): -0.0\n",
      "C (28743): -0.0\n",
      ") (28731): -0.0\n",
      "the (272): -0.0\n",
      "desert (13453): -0.0\n",
      "\n",
      " (13): -0.0\n",
      "       (5390): -0.0\n",
      "( (325): -0.0\n",
      "D (28757): -0.0\n",
      ") (28731): -0.0\n",
      "apartment (9585): -0.0\n",
      "\n",
      " (13): -0.0\n",
      "       (5390): -0.0\n",
      "( (325): -0.0\n",
      "E (28749): -0.0\n",
      ") (28731): -0.0\n",
      "road (3878): -0.0\n",
      "block (3356): -0.0\n",
      "\n",
      " (13): -0.0\n",
      "       (5390): -0.0\n",
      "Answer (26307): -0.0\n",
      ": (28747): -0.0\n",
      "[ (733): -0.0\n",
      "/ (28748): -0.0\n",
      "INST (16289): -0.0\n",
      "] (28793): -0.0\n",
      "The (415): -0.0\n",
      "answer (4372): -1.665140986442566\n",
      "is (349): -0.08603980392217636\n",
      "( (325): -0.6777109503746033\n",
      "A (28741): -0.962875247001648\n",
      "). (609): -0.5121680498123169\n"
     ]
    }
   ],
   "source": [
    "answer_prefix = answer_prefix.to(base_model.device)\n",
    "binary_mask = binary_mask.to(base_model.device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = base_model(answer_prefix)\n",
    "\n",
    "logprobs = torch.log_softmax(outputs.logits, dim=-1).detach()\n",
    "\n",
    "logprobs = logprobs[:, :-1, :]\n",
    "answer_prefix  = answer_prefix [:, 1:]\n",
    "\n",
    "# get logprobs corresponding to specific input_id tokens (out of all vocab logprob distribution)\n",
    "gen_logprobs = torch.gather(logprobs, 2, answer_prefix[:, :, None]).squeeze(-1)\n",
    "\n",
    "masked_logprobs = gen_logprobs * binary_mask[:, 1:].float() # extract logprobs from answer tokens\n",
    "\n",
    "total_summed_logprobs = masked_logprobs.sum(dim=1)\n",
    "\n",
    "print_logging = True\n",
    "if print_logging:\n",
    "    print(\"summed_probs: \", total_summed_logprobs.shape)\n",
    "\n",
    "    for input_sentence, input_probs in zip(answer_prefix , masked_logprobs):\n",
    "    # for input_sentence, input_probs in zip(batch_ids , gen_logprobs): # check all logprobs\n",
    "        for token, p in zip(input_sentence, input_probs):\n",
    "            if token not in instruct_tokenizer.all_special_ids:\n",
    "                print(f\"{instruct_tokenizer.decode(token)} ({token}): {p.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_paths_with_base_model(q_A_tensor, A_length, model, tokenizer):\n",
    "    q_A_tensor = q_A_tensor.to(model.device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(q_A_tensor)\n",
    "    \n",
    "    logprobs = torch.log_softmax(outputs.logits, dim=1).detach()\n",
    "    logprobs = logprobs[:, :-1, :]\n",
    "    q_A_tensor = q_A_tensor[:, 1:]\n",
    "\n",
    "    gen_logprobs = torch.gather(logprobs, 2, q_A_tensor[:, :, None]).squeeze(-1)\n",
    "    masked_logprobs = gen_logprobs\n",
    "    masked_logprobs[:, :-A_length] = 0\n",
    "    summed_logprobs = masked_logprobs.sum(dim=1)\n",
    "\n",
    "    # print_all_logprobs = False \n",
    "    print_all_logprobs = False\n",
    "    if print_all_logprobs:\n",
    "            print(\"summed_probs: \", summed_logprobs.shape)\n",
    "            for input_sentence, input_probs in zip(q_A_tensor , masked_logprobs):\n",
    "            # for input_sentence, input_probs in zip(s1_s2_tensor , gen_logprobs): # check all logprobs\n",
    "                for token, p in zip(input_sentence, input_probs):\n",
    "                    if token not in tokenizer.all_special_ids:\n",
    "                        print(f\"{tokenizer.decode(token)} ({token}): {p.item()}\")\n",
    "\n",
    "    return summed_logprobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "summed_probs:  torch.Size([1])\n",
      "[ (733): 0.0\n",
      "INST (16289): 0.0\n",
      "] (28793): 0.0\n",
      "Question (22478): 0.0\n",
      ": (28747): 0.0\n",
      "Sam (4157): 0.0\n",
      "my (1916): 0.0\n",
      "wanted (2613): 0.0\n",
      "to (298): 0.0\n",
      "go (576): 0.0\n",
      "to (298): 0.0\n",
      "where (970): 0.0\n",
      "the (272): 0.0\n",
      "people (905): 0.0\n",
      "were (654): 0.0\n",
      ". (28723): 0.0\n",
      " (28705): 0.0\n",
      "Where (6926): 0.0\n",
      "might (1659): 0.0\n",
      "he (400): 0.0\n",
      "go (576): 0.0\n",
      "? (28804): 0.0\n",
      "\n",
      " (13): 0.0\n",
      "       (5390): 0.0\n",
      "Cho (25405): 0.0\n",
      "ices (1214): 0.0\n",
      ": (28747): 0.0\n",
      "\n",
      " (13): 0.0\n",
      "       (5390): 0.0\n",
      "( (325): 0.0\n",
      "A (28741): 0.0\n",
      ") (28731): 0.0\n",
      "race (5941): 0.0\n",
      "track (3508): 0.0\n",
      "\n",
      " (13): 0.0\n",
      "       (5390): 0.0\n",
      "( (325): 0.0\n",
      "B (28760): 0.0\n",
      ") (28731): 0.0\n",
      "pop (1852): 0.0\n",
      "ulated (6432): 0.0\n",
      "areas (5020): 0.0\n",
      "\n",
      " (13): 0.0\n",
      "       (5390): 0.0\n",
      "( (325): 0.0\n",
      "C (28743): 0.0\n",
      ") (28731): 0.0\n",
      "the (272): 0.0\n",
      "desert (13453): 0.0\n",
      "\n",
      " (13): 0.0\n",
      "       (5390): 0.0\n",
      "( (325): 0.0\n",
      "D (28757): 0.0\n",
      ") (28731): 0.0\n",
      "apartment (9585): 0.0\n",
      "\n",
      " (13): 0.0\n",
      "       (5390): 0.0\n",
      "( (325): 0.0\n",
      "E (28749): 0.0\n",
      ") (28731): 0.0\n",
      "road (3878): 0.0\n",
      "block (3356): 0.0\n",
      "\n",
      " (13): 0.0\n",
      "       (5390): 0.0\n",
      "Answer (26307): 0.0\n",
      ": (28747): 0.0\n",
      "[ (733): 0.0\n",
      "/ (28748): 0.0\n",
      "INST (16289): 0.0\n",
      "] (28793): 0.0\n",
      "The (415): -4.87017822265625\n",
      "answer (4372): -0.4944964051246643\n",
      "is (349): -0.05679812654852867\n",
      "( (325): -6.097057819366455\n",
      "A (28741): -0.9112613201141357\n",
      "). (609): -0.005601187236607075\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([-12.4354], device='cuda:0')"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A_length = answer_prefix.shape[1] - question_tensor.shape[1]\n",
    "\n",
    "summed_logprobs = score_paths_with_base_model(answer_prefix, A_length, base_model, instruct_tokenizer)\n",
    "summed_logprobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "\n",
    "csqa_df = pd.read_csv('data/commonsense_qa_train.csv')\n",
    "csqa_df['choices'] = csqa_df['choices'].apply(ast.literal_eval)\n",
    "\n",
    "question_tensor = instruct_tokenizer.apply_chat_template(chat, return_tensors='pt', tokenize=True)\n",
    "\n",
    "def compare(letter):\n",
    "    df_subset = df[df['answer_letter'] == letter]\n",
    "\n",
    "    total_summed_logprobs_tensor = torch.tensor(df_subset['total_summed_logprobs'].values, dtype=torch.float32)\n",
    "    logsumexp_result = torch.logsumexp(total_summed_logprobs_tensor, dim=0)\n",
    "\n",
    "    print(f\"LogSumExp of total_summed_logprobs for answer_letter '{letter}':\", logsumexp_result.item())\n",
    "\n",
    "    q_num = 1\n",
    "\n",
    "    prompt = f\"\"\"Question: {csqa_df['question'][q_num]}\n",
    "            Choices:\n",
    "            (A) {csqa_df['choices'][q_num]['text'][0]}\n",
    "            (B) {csqa_df['choices'][q_num]['text'][1]}\n",
    "            (C) {csqa_df['choices'][q_num]['text'][2]}\n",
    "            (D) {csqa_df['choices'][q_num]['text'][3]}\n",
    "            (E) {csqa_df['choices'][q_num]['text'][4]}\n",
    "            Answer:\"\"\"\n",
    "\n",
    "    chat = [{\"role\":\"user\", \"content\": prompt}]\n",
    "\n",
    "    answer_prefix = instruct_tokenizer.encode(\n",
    "        instruct_tokenizer.apply_chat_template(chat, tokenize=False) + f\" The answer is ({letter}).\", \n",
    "        return_tensors='pt', \n",
    "        add_special_tokens=False\n",
    "        )\n",
    "    \n",
    "    A_length = answer_prefix.shape[1] - question_tensor.shape[1]\n",
    "\n",
    "    summed_logprobs = score_paths_with_base_model(answer_prefix, A_length, base_model, instruct_tokenizer)\n",
    "    print(f'P({letter}) = ', summed_logprobs)\n",
    "\n",
    "    return logsumexp_result, summed_logprobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogSumExp of total_summed_logprobs for answer_letter 'A': -75.19791412353516\n",
      "summed_probs:  torch.Size([1])\n",
      "[ (733): 0.0\n",
      "INST (16289): 0.0\n",
      "] (28793): 0.0\n",
      "Question (22478): 0.0\n",
      ": (28747): 0.0\n",
      "Sam (4157): 0.0\n",
      "my (1916): 0.0\n",
      "wanted (2613): 0.0\n",
      "to (298): 0.0\n",
      "go (576): 0.0\n",
      "to (298): 0.0\n",
      "where (970): 0.0\n",
      "the (272): 0.0\n",
      "people (905): 0.0\n",
      "were (654): 0.0\n",
      ". (28723): 0.0\n",
      " (28705): 0.0\n",
      "Where (6926): 0.0\n",
      "might (1659): 0.0\n",
      "he (400): 0.0\n",
      "go (576): 0.0\n",
      "? (28804): 0.0\n",
      "\n",
      " (13): 0.0\n",
      "           (17422): 0.0\n",
      "Cho (25405): 0.0\n",
      "ices (1214): 0.0\n",
      ": (28747): 0.0\n",
      "\n",
      " (13): 0.0\n",
      "           (17422): 0.0\n",
      "( (325): 0.0\n",
      "A (28741): 0.0\n",
      ") (28731): 0.0\n",
      "race (5941): 0.0\n",
      "track (3508): 0.0\n",
      "\n",
      " (13): 0.0\n",
      "           (17422): 0.0\n",
      "( (325): 0.0\n",
      "B (28760): 0.0\n",
      ") (28731): 0.0\n",
      "pop (1852): 0.0\n",
      "ulated (6432): 0.0\n",
      "areas (5020): 0.0\n",
      "\n",
      " (13): 0.0\n",
      "           (17422): 0.0\n",
      "( (325): 0.0\n",
      "C (28743): 0.0\n",
      ") (28731): 0.0\n",
      "the (272): 0.0\n",
      "desert (13453): 0.0\n",
      "\n",
      " (13): 0.0\n",
      "           (17422): 0.0\n",
      "( (325): 0.0\n",
      "D (28757): 0.0\n",
      ") (28731): 0.0\n",
      "apartment (9585): 0.0\n",
      "\n",
      " (13): 0.0\n",
      "           (17422): 0.0\n",
      "( (325): 0.0\n",
      "E (28749): 0.0\n",
      ") (28731): 0.0\n",
      "road (3878): 0.0\n",
      "block (3356): 0.0\n",
      "\n",
      " (13): 0.0\n",
      "           (17422): 0.0\n",
      "Answer (26307): 0.0\n",
      ": (28747): 0.0\n",
      "[ (733): 0.0\n",
      "/ (28748): 0.0\n",
      "INST (16289): 0.0\n",
      "] (28793): 0.0\n",
      "The (415): -5.00224494934082\n",
      "answer (4372): -0.5312487483024597\n",
      "is (349): -0.0580812506377697\n",
      "( (325): -6.075214385986328\n",
      "A (28741): -0.7795207500457764\n",
      "). (609): -0.006618602201342583\n",
      "P(A) =  tensor([-12.4529], device='cuda:0')\n",
      "LogSumExp of total_summed_logprobs for answer_letter 'B': -112.43409729003906\n",
      "summed_probs:  torch.Size([1])\n",
      "[ (733): 0.0\n",
      "INST (16289): 0.0\n",
      "] (28793): 0.0\n",
      "Question (22478): 0.0\n",
      ": (28747): 0.0\n",
      "Sam (4157): 0.0\n",
      "my (1916): 0.0\n",
      "wanted (2613): 0.0\n",
      "to (298): 0.0\n",
      "go (576): 0.0\n",
      "to (298): 0.0\n",
      "where (970): 0.0\n",
      "the (272): 0.0\n",
      "people (905): 0.0\n",
      "were (654): 0.0\n",
      ". (28723): 0.0\n",
      " (28705): 0.0\n",
      "Where (6926): 0.0\n",
      "might (1659): 0.0\n",
      "he (400): 0.0\n",
      "go (576): 0.0\n",
      "? (28804): 0.0\n",
      "\n",
      " (13): 0.0\n",
      "           (17422): 0.0\n",
      "Cho (25405): 0.0\n",
      "ices (1214): 0.0\n",
      ": (28747): 0.0\n",
      "\n",
      " (13): 0.0\n",
      "           (17422): 0.0\n",
      "( (325): 0.0\n",
      "A (28741): 0.0\n",
      ") (28731): 0.0\n",
      "race (5941): 0.0\n",
      "track (3508): 0.0\n",
      "\n",
      " (13): 0.0\n",
      "           (17422): 0.0\n",
      "( (325): 0.0\n",
      "B (28760): 0.0\n",
      ") (28731): 0.0\n",
      "pop (1852): 0.0\n",
      "ulated (6432): 0.0\n",
      "areas (5020): 0.0\n",
      "\n",
      " (13): 0.0\n",
      "           (17422): 0.0\n",
      "( (325): 0.0\n",
      "C (28743): 0.0\n",
      ") (28731): 0.0\n",
      "the (272): 0.0\n",
      "desert (13453): 0.0\n",
      "\n",
      " (13): 0.0\n",
      "           (17422): 0.0\n",
      "( (325): 0.0\n",
      "D (28757): 0.0\n",
      ") (28731): 0.0\n",
      "apartment (9585): 0.0\n",
      "\n",
      " (13): 0.0\n",
      "           (17422): 0.0\n",
      "( (325): 0.0\n",
      "E (28749): 0.0\n",
      ") (28731): 0.0\n",
      "road (3878): 0.0\n",
      "block (3356): 0.0\n",
      "\n",
      " (13): 0.0\n",
      "           (17422): 0.0\n",
      "Answer (26307): 0.0\n",
      ": (28747): 0.0\n",
      "[ (733): 0.0\n",
      "/ (28748): 0.0\n",
      "INST (16289): 0.0\n",
      "] (28793): 0.0\n",
      "The (415): -4.987701416015625\n",
      "answer (4372): -0.531226634979248\n",
      "is (349): -0.05807371437549591\n",
      "( (325): -6.075204849243164\n",
      "B (28760): -2.3532302379608154\n",
      "). (609): -0.0051583293825387955\n",
      "P(B) =  tensor([-14.0106], device='cuda:0')\n",
      "LogSumExp of total_summed_logprobs for answer_letter 'C': -207.63845825195312\n",
      "summed_probs:  torch.Size([1])\n",
      "[ (733): 0.0\n",
      "INST (16289): 0.0\n",
      "] (28793): 0.0\n",
      "Question (22478): 0.0\n",
      ": (28747): 0.0\n",
      "Sam (4157): 0.0\n",
      "my (1916): 0.0\n",
      "wanted (2613): 0.0\n",
      "to (298): 0.0\n",
      "go (576): 0.0\n",
      "to (298): 0.0\n",
      "where (970): 0.0\n",
      "the (272): 0.0\n",
      "people (905): 0.0\n",
      "were (654): 0.0\n",
      ". (28723): 0.0\n",
      " (28705): 0.0\n",
      "Where (6926): 0.0\n",
      "might (1659): 0.0\n",
      "he (400): 0.0\n",
      "go (576): 0.0\n",
      "? (28804): 0.0\n",
      "\n",
      " (13): 0.0\n",
      "           (17422): 0.0\n",
      "Cho (25405): 0.0\n",
      "ices (1214): 0.0\n",
      ": (28747): 0.0\n",
      "\n",
      " (13): 0.0\n",
      "           (17422): 0.0\n",
      "( (325): 0.0\n",
      "A (28741): 0.0\n",
      ") (28731): 0.0\n",
      "race (5941): 0.0\n",
      "track (3508): 0.0\n",
      "\n",
      " (13): 0.0\n",
      "           (17422): 0.0\n",
      "( (325): 0.0\n",
      "B (28760): 0.0\n",
      ") (28731): 0.0\n",
      "pop (1852): 0.0\n",
      "ulated (6432): 0.0\n",
      "areas (5020): 0.0\n",
      "\n",
      " (13): 0.0\n",
      "           (17422): 0.0\n",
      "( (325): 0.0\n",
      "C (28743): 0.0\n",
      ") (28731): 0.0\n",
      "the (272): 0.0\n",
      "desert (13453): 0.0\n",
      "\n",
      " (13): 0.0\n",
      "           (17422): 0.0\n",
      "( (325): 0.0\n",
      "D (28757): 0.0\n",
      ") (28731): 0.0\n",
      "apartment (9585): 0.0\n",
      "\n",
      " (13): 0.0\n",
      "           (17422): 0.0\n",
      "( (325): 0.0\n",
      "E (28749): 0.0\n",
      ") (28731): 0.0\n",
      "road (3878): 0.0\n",
      "block (3356): 0.0\n",
      "\n",
      " (13): 0.0\n",
      "           (17422): 0.0\n",
      "Answer (26307): 0.0\n",
      ": (28747): 0.0\n",
      "[ (733): 0.0\n",
      "/ (28748): 0.0\n",
      "INST (16289): 0.0\n",
      "] (28793): 0.0\n",
      "The (415): -5.068179130554199\n",
      "answer (4372): -0.5312883853912354\n",
      "is (349): -0.058078549802303314\n",
      "( (325): -6.075207710266113\n",
      "C (28743): -5.755183219909668\n",
      "). (609): -0.009615653194487095\n",
      "P(C) =  tensor([-17.4976], device='cuda:0')\n",
      "LogSumExp of total_summed_logprobs for answer_letter 'D': -126.33074951171875\n",
      "summed_probs:  torch.Size([1])\n",
      "[ (733): 0.0\n",
      "INST (16289): 0.0\n",
      "] (28793): 0.0\n",
      "Question (22478): 0.0\n",
      ": (28747): 0.0\n",
      "Sam (4157): 0.0\n",
      "my (1916): 0.0\n",
      "wanted (2613): 0.0\n",
      "to (298): 0.0\n",
      "go (576): 0.0\n",
      "to (298): 0.0\n",
      "where (970): 0.0\n",
      "the (272): 0.0\n",
      "people (905): 0.0\n",
      "were (654): 0.0\n",
      ". (28723): 0.0\n",
      " (28705): 0.0\n",
      "Where (6926): 0.0\n",
      "might (1659): 0.0\n",
      "he (400): 0.0\n",
      "go (576): 0.0\n",
      "? (28804): 0.0\n",
      "\n",
      " (13): 0.0\n",
      "           (17422): 0.0\n",
      "Cho (25405): 0.0\n",
      "ices (1214): 0.0\n",
      ": (28747): 0.0\n",
      "\n",
      " (13): 0.0\n",
      "           (17422): 0.0\n",
      "( (325): 0.0\n",
      "A (28741): 0.0\n",
      ") (28731): 0.0\n",
      "race (5941): 0.0\n",
      "track (3508): 0.0\n",
      "\n",
      " (13): 0.0\n",
      "           (17422): 0.0\n",
      "( (325): 0.0\n",
      "B (28760): 0.0\n",
      ") (28731): 0.0\n",
      "pop (1852): 0.0\n",
      "ulated (6432): 0.0\n",
      "areas (5020): 0.0\n",
      "\n",
      " (13): 0.0\n",
      "           (17422): 0.0\n",
      "( (325): 0.0\n",
      "C (28743): 0.0\n",
      ") (28731): 0.0\n",
      "the (272): 0.0\n",
      "desert (13453): 0.0\n",
      "\n",
      " (13): 0.0\n",
      "           (17422): 0.0\n",
      "( (325): 0.0\n",
      "D (28757): 0.0\n",
      ") (28731): 0.0\n",
      "apartment (9585): 0.0\n",
      "\n",
      " (13): 0.0\n",
      "           (17422): 0.0\n",
      "( (325): 0.0\n",
      "E (28749): 0.0\n",
      ") (28731): 0.0\n",
      "road (3878): 0.0\n",
      "block (3356): 0.0\n",
      "\n",
      " (13): 0.0\n",
      "           (17422): 0.0\n",
      "Answer (26307): 0.0\n",
      ": (28747): 0.0\n",
      "[ (733): 0.0\n",
      "/ (28748): 0.0\n",
      "INST (16289): 0.0\n",
      "] (28793): 0.0\n",
      "The (415): -5.01743745803833\n",
      "answer (4372): -0.5314693450927734\n",
      "is (349): -0.058072928339242935\n",
      "( (325): -6.075207710266113\n",
      "D (28757): -4.517163276672363\n",
      "). (609): -0.0051583293825387955\n",
      "P(D) =  tensor([-16.2045], device='cuda:0')\n",
      "LogSumExp of total_summed_logprobs for answer_letter 'E': -161.99684143066406\n",
      "summed_probs:  torch.Size([1])\n",
      "[ (733): 0.0\n",
      "INST (16289): 0.0\n",
      "] (28793): 0.0\n",
      "Question (22478): 0.0\n",
      ": (28747): 0.0\n",
      "Sam (4157): 0.0\n",
      "my (1916): 0.0\n",
      "wanted (2613): 0.0\n",
      "to (298): 0.0\n",
      "go (576): 0.0\n",
      "to (298): 0.0\n",
      "where (970): 0.0\n",
      "the (272): 0.0\n",
      "people (905): 0.0\n",
      "were (654): 0.0\n",
      ". (28723): 0.0\n",
      " (28705): 0.0\n",
      "Where (6926): 0.0\n",
      "might (1659): 0.0\n",
      "he (400): 0.0\n",
      "go (576): 0.0\n",
      "? (28804): 0.0\n",
      "\n",
      " (13): 0.0\n",
      "           (17422): 0.0\n",
      "Cho (25405): 0.0\n",
      "ices (1214): 0.0\n",
      ": (28747): 0.0\n",
      "\n",
      " (13): 0.0\n",
      "           (17422): 0.0\n",
      "( (325): 0.0\n",
      "A (28741): 0.0\n",
      ") (28731): 0.0\n",
      "race (5941): 0.0\n",
      "track (3508): 0.0\n",
      "\n",
      " (13): 0.0\n",
      "           (17422): 0.0\n",
      "( (325): 0.0\n",
      "B (28760): 0.0\n",
      ") (28731): 0.0\n",
      "pop (1852): 0.0\n",
      "ulated (6432): 0.0\n",
      "areas (5020): 0.0\n",
      "\n",
      " (13): 0.0\n",
      "           (17422): 0.0\n",
      "( (325): 0.0\n",
      "C (28743): 0.0\n",
      ") (28731): 0.0\n",
      "the (272): 0.0\n",
      "desert (13453): 0.0\n",
      "\n",
      " (13): 0.0\n",
      "           (17422): 0.0\n",
      "( (325): 0.0\n",
      "D (28757): 0.0\n",
      ") (28731): 0.0\n",
      "apartment (9585): 0.0\n",
      "\n",
      " (13): 0.0\n",
      "           (17422): 0.0\n",
      "( (325): 0.0\n",
      "E (28749): 0.0\n",
      ") (28731): 0.0\n",
      "road (3878): 0.0\n",
      "block (3356): 0.0\n",
      "\n",
      " (13): 0.0\n",
      "           (17422): 0.0\n",
      "Answer (26307): 0.0\n",
      ": (28747): 0.0\n",
      "[ (733): 0.0\n",
      "/ (28748): 0.0\n",
      "INST (16289): 0.0\n",
      "] (28793): 0.0\n",
      "The (415): -5.017402172088623\n",
      "answer (4372): -0.5313647985458374\n",
      "is (349): -0.058073490858078\n",
      "( (325): -6.075201988220215\n",
      "E (28749): -3.369080066680908\n",
      "). (609): -0.006618602201342583\n",
      "P(E) =  tensor([-15.0577], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "for c in 'ABCDE':\n",
    "    compare(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>question</th>\n",
       "      <th>question_concept</th>\n",
       "      <th>choices</th>\n",
       "      <th>answerKey</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>075e483d21c29a511267ef62bedc0461</td>\n",
       "      <td>The sanctions against the school were a punish...</td>\n",
       "      <td>punishing</td>\n",
       "      <td>{'label': ['A', 'B', 'C', 'D', 'E'], 'text': [...</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>61fe6e879ff18686d7552425a36344c8</td>\n",
       "      <td>Sammy wanted to go to where the people were.  ...</td>\n",
       "      <td>people</td>\n",
       "      <td>{'label': ['A', 'B', 'C', 'D', 'E'], 'text': [...</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4c1cb0e95b99f72d55c068ba0255c54d</td>\n",
       "      <td>To locate a choker not located in a jewelry bo...</td>\n",
       "      <td>choker</td>\n",
       "      <td>{'label': ['A', 'B', 'C', 'D', 'E'], 'text': [...</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>02e821a3e53cb320790950aab4489e85</td>\n",
       "      <td>Google Maps and other highway and street GPS s...</td>\n",
       "      <td>highway</td>\n",
       "      <td>{'label': ['A', 'B', 'C', 'D', 'E'], 'text': [...</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>23505889b94e880c3e89cff4ba119860</td>\n",
       "      <td>The fox walked from the city into the forest, ...</td>\n",
       "      <td>fox</td>\n",
       "      <td>{'label': ['A', 'B', 'C', 'D', 'E'], 'text': [...</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 id  \\\n",
       "0  075e483d21c29a511267ef62bedc0461   \n",
       "1  61fe6e879ff18686d7552425a36344c8   \n",
       "2  4c1cb0e95b99f72d55c068ba0255c54d   \n",
       "3  02e821a3e53cb320790950aab4489e85   \n",
       "4  23505889b94e880c3e89cff4ba119860   \n",
       "\n",
       "                                            question question_concept  \\\n",
       "0  The sanctions against the school were a punish...        punishing   \n",
       "1  Sammy wanted to go to where the people were.  ...           people   \n",
       "2  To locate a choker not located in a jewelry bo...           choker   \n",
       "3  Google Maps and other highway and street GPS s...          highway   \n",
       "4  The fox walked from the city into the forest, ...              fox   \n",
       "\n",
       "                                             choices answerKey  \n",
       "0  {'label': ['A', 'B', 'C', 'D', 'E'], 'text': [...         A  \n",
       "1  {'label': ['A', 'B', 'C', 'D', 'E'], 'text': [...         B  \n",
       "2  {'label': ['A', 'B', 'C', 'D', 'E'], 'text': [...         A  \n",
       "3  {'label': ['A', 'B', 'C', 'D', 'E'], 'text': [...         D  \n",
       "4  {'label': ['A', 'B', 'C', 'D', 'E'], 'text': [...         C  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csqa_df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "reason",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
