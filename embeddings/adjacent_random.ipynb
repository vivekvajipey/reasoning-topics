{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import umap\n",
    "from sklearn.manifold import TSNE\n",
    "from scipy.spatial import distance\n",
    "import warnings\n",
    "import re\n",
    "import random\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import embedding_plotting\n",
    "import trace_utils\n",
    "importlib.reload(embedding_plotting)\n",
    "importlib.reload(trace_utils)\n",
    "\n",
    "\n",
    "from embedding_plotting import DimensionalViz\n",
    "from embedding_plotting import cot_step_print\n",
    "from trace_utils import split_cot\n",
    "from trace_utils import compute_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "gsm_df = pd.read_csv('data/cot_data_50_start_sentences_autosplit.csv')\n",
    "# gsm_df['CoT Sentences'] = gsm_df['CoT Sentences'].apply(split_cot)\n",
    "\n",
    "# gsm_df = pd.read_csv('data/cot_data_50_start_sentences_sentsplit.csv')\n",
    "gsm_df['CoT Sentences'] = gsm_df['CoT Sentences'].apply(ast.literal_eval)\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(gsm_df['CoT Sentences'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "gsm_df['CoT Length'] = gsm_df['CoT Sentences'].apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "def plot_cot_step_metrics(cot_collection):\n",
    "    \"\"\"\n",
    "    Plots metric sequence for all inputted sentences\n",
    "    \"\"\"\n",
    "    embeddings_collection = []\n",
    "    metrics_adjacent_collection = []\n",
    "    metrics_random_collection = []\n",
    "    for trace in cot_collection:\n",
    "        embeddings = [model.encode(step) for step in trace]\n",
    "        embeddings_collection.append(embeddings)\n",
    "        metrics_adjacent = []\n",
    "        metrics_random = []\n",
    "        for i in range(len(embeddings) - 1):\n",
    "            emb1 = embeddings[i]\n",
    "            emb2 = embeddings[i + 1]\n",
    "\n",
    "            # Compute metric for adjacent steps\n",
    "            metric_adjacent = distance.euclidean(emb1, emb2)\n",
    "            metrics_adjacent.append(metric_adjacent)\n",
    "\n",
    "            # Compute metric for random steps\n",
    "            other_embeddings = embeddings[:i] + embeddings[i+2:]  # Exclude the current and next step's embeddings\n",
    "            emb_random = random.choice(other_embeddings)\n",
    "            metric_random = distance.euclidean(emb1, emb_random)\n",
    "            metrics_random.append(metric_random)\n",
    "\n",
    "        metrics_adjacent_collection.append(metrics_adjacent)\n",
    "        metrics_random_collection.append(metrics_random)\n",
    "\n",
    "    # Plotting\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    colors = ['b', 'g', 'r', 'c', 'm', 'y', 'k']  # List of colors for the traces\n",
    "    for i, (metrics_adjacent, metrics_random) in enumerate(zip(metrics_adjacent_collection, metrics_random_collection)):\n",
    "        indices = list(range(len(metrics_adjacent)))\n",
    "        color = colors[i % len(colors)]  # Select a color from the list\n",
    "        plt.plot(indices, metrics_adjacent, label=f'Trace {i+1} (Adjacent)', color=color)\n",
    "        plt.plot(indices, metrics_random, label=f'Trace {i+1} (Random)', linestyle='dashed', color=color)\n",
    "\n",
    "    plt.xlabel('Step Index')\n",
    "    plt.ylabel('Euclidean Distance')\n",
    "    plt.title('Euclidean Distance between Successive and Random Embeddings for Each Trace')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cot_collection_1 = []\n",
    "cot_collection_1.append(['Betty sold Apples to 48 of her friends in April, and then she sold half as many Apples in May. How many Apples did Betty sell altogether in April and May?',\n",
    " \"First, let's calculate how many Apples Betty sold in May. We know that she sold half as many Apples in May as she did in April. So, we can find this by dividing the number of Apples she sold in April by 2. 48 Apples / 2 = 24 Apples Therefore, Betty sold 24 Apples in May.\",\n",
    " \"Now, let's calculate how many Apples she sold altogether in April and May. We can find this by adding the number of Apples she sold in April and the number of Apples she sold in May. 48 Apples + 24 Apples = 72 Apples\",\n",
    " 'Therefore, Betty sold a total of 72 Apples in April and May.'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_cot_step_metrics(cot_collection_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_cot(cot_collection[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(sampled_df['CoT Sentences'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_df['CoT Sentences'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_df = gsm_df.sample(3)\n",
    "cot_collection = []\n",
    "for i, trace in enumerate(sampled_df['CoT Sentences'].tolist()):\n",
    "    first_three_words = \" \".join(sampled_df['Prompt'].iloc[i].split()[:3])\n",
    "    print(\"Prompts:\")\n",
    "    print(f\"Trace {i + 1}: {first_three_words}...\")\n",
    "    # cot_collection.append(split_cot(trace))\n",
    "    cot_collection.append(trace)\n",
    "plot_cot_step_metrics(cot_collection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gsm_df[gsm_df['Prompt'].str.startswith('A deep-sea monster')].index[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gsm_df.iloc[10]['Answer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, step in enumerate(gsm_df.iloc[10]['CoT Sentences']):\n",
    "    print(f\"Step {i}: \", step)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aggregating Metrics Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_list = []\n",
    "cot_steps_list = []\n",
    "original_text_list = []\n",
    "metrics_list = []\n",
    "\n",
    "for i in range(len(gsm_df)):\n",
    "    question = gsm_df['Prompt'][i]\n",
    "    cot_reasoning = gsm_df['CoT Sentences'][i]\n",
    "    # cot_reasoning.insert(0, question)\n",
    "    cot_steps_list.append(cot_reasoning)\n",
    "    cot_embeddings = model.encode(cot_reasoning)\n",
    "    \n",
    "    embeddings_list.append(cot_embeddings)\n",
    "    original_text_list.append(cot_reasoning)\n",
    "    metrics_list.append(compute_metrics(cot_embeddings))\n",
    "\n",
    "# Convert lists to DataFrame\n",
    "metrics_df = pd.DataFrame(metrics_list)\n",
    "metrics_df['Original_Text'] = original_text_list\n",
    "metrics_df['QnA_Steps'] = cot_steps_list\n",
    "metrics_df['Embeddings'] = embeddings_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cosine_similarity</th>\n",
       "      <th>euclidean_distance</th>\n",
       "      <th>manhattan_distance</th>\n",
       "      <th>chebyshev_distance</th>\n",
       "      <th>random_cosine_similarity</th>\n",
       "      <th>random_euclidean_distance</th>\n",
       "      <th>random_manhattan_distance</th>\n",
       "      <th>random_chebyshev_distance</th>\n",
       "      <th>Original_Text</th>\n",
       "      <th>QnA_Steps</th>\n",
       "      <th>Embeddings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[0.9199719429016113, 0.8663821220397949, 0.780...</td>\n",
       "      <td>[0.40007010102272034, 0.5169485211372375, 0.66...</td>\n",
       "      <td>[6.096766, 8.09886, 10.323913]</td>\n",
       "      <td>[0.057846904, 0.07872835, 0.10761879]</td>\n",
       "      <td>[0.9199719429016113, 0.8757071495056152, 0.849...</td>\n",
       "      <td>[0.40007010102272034, 0.49858367443084717, 0.5...</td>\n",
       "      <td>[6.096766, 7.7720566, 8.411891, 10.323913]</td>\n",
       "      <td>[0.057846904, 0.06956047, 0.104543395, 0.10761...</td>\n",
       "      <td>[Natalia sold clips to 48 of her friends in Ap...</td>\n",
       "      <td>[Natalia sold clips to 48 of her friends in Ap...</td>\n",
       "      <td>[[0.016148278, -0.029351903, 0.058499925, 0.00...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[0.7146852016448975, 0.5657150745391846, 0.560...</td>\n",
       "      <td>[0.7554001212120056, 0.9319709539413452, 0.937...</td>\n",
       "      <td>[12.033253, 14.630195, 14.400565]</td>\n",
       "      <td>[0.11994025, 0.1259255, 0.1891798]</td>\n",
       "      <td>[0.6630569100379944, 0.5657150745391846, 0.565...</td>\n",
       "      <td>[0.8209056854248047, 0.9319709539413452, 0.931...</td>\n",
       "      <td>[12.6781645, 14.630195, 14.630195, 13.905078]</td>\n",
       "      <td>[0.17126317, 0.1259255, 0.1259255, 0.13138106]</td>\n",
       "      <td>[Weng earns $12 an hour for babysitting. Yeste...</td>\n",
       "      <td>[Weng earns $12 an hour for babysitting. Yeste...</td>\n",
       "      <td>[[0.025501108, 0.070720375, 0.045118127, 0.035...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   cosine_similarity  \\\n",
       "0  [0.9199719429016113, 0.8663821220397949, 0.780...   \n",
       "1  [0.7146852016448975, 0.5657150745391846, 0.560...   \n",
       "\n",
       "                                  euclidean_distance  \\\n",
       "0  [0.40007010102272034, 0.5169485211372375, 0.66...   \n",
       "1  [0.7554001212120056, 0.9319709539413452, 0.937...   \n",
       "\n",
       "                  manhattan_distance                     chebyshev_distance  \\\n",
       "0     [6.096766, 8.09886, 10.323913]  [0.057846904, 0.07872835, 0.10761879]   \n",
       "1  [12.033253, 14.630195, 14.400565]     [0.11994025, 0.1259255, 0.1891798]   \n",
       "\n",
       "                            random_cosine_similarity  \\\n",
       "0  [0.9199719429016113, 0.8757071495056152, 0.849...   \n",
       "1  [0.6630569100379944, 0.5657150745391846, 0.565...   \n",
       "\n",
       "                           random_euclidean_distance  \\\n",
       "0  [0.40007010102272034, 0.49858367443084717, 0.5...   \n",
       "1  [0.8209056854248047, 0.9319709539413452, 0.931...   \n",
       "\n",
       "                       random_manhattan_distance  \\\n",
       "0     [6.096766, 7.7720566, 8.411891, 10.323913]   \n",
       "1  [12.6781645, 14.630195, 14.630195, 13.905078]   \n",
       "\n",
       "                           random_chebyshev_distance  \\\n",
       "0  [0.057846904, 0.06956047, 0.104543395, 0.10761...   \n",
       "1     [0.17126317, 0.1259255, 0.1259255, 0.13138106]   \n",
       "\n",
       "                                       Original_Text  \\\n",
       "0  [Natalia sold clips to 48 of her friends in Ap...   \n",
       "1  [Weng earns $12 an hour for babysitting. Yeste...   \n",
       "\n",
       "                                           QnA_Steps  \\\n",
       "0  [Natalia sold clips to 48 of her friends in Ap...   \n",
       "1  [Weng earns $12 an hour for babysitting. Yeste...   \n",
       "\n",
       "                                          Embeddings  \n",
       "0  [[0.016148278, -0.029351903, 0.058499925, 0.00...  \n",
       "1  [[0.025501108, 0.070720375, 0.045118127, 0.035...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_metrics(metrics):\n",
    "    min_val = min(metrics)\n",
    "    max_val = max(metrics)\n",
    "    range_val = max_val - min_val\n",
    "    if range_val > 0:\n",
    "        normalized_metrics = [(m - min_val) / range_val for m in metrics]\n",
    "    else:\n",
    "        normalized_metrics = [0 for _ in metrics]\n",
    "    return normalized_metrics\n",
    "\n",
    "metrics_df['euclidean_distance_normalized'] = metrics_df['euclidean_distance'].apply(normalize_metrics)\n",
    "metrics_df['random_euclidean_distance_normalized'] = metrics_df['random_' + 'euclidean_distance'].apply(normalize_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Natalia sold clips to 48 of her friends in April, and then she sold half as many clips in May. How many clips did Natalia sell altogether in April and May?',\n",
       " \"First, let's calculate how many clips Natalia sold in May. We know that she sold half as many clips in May as she did in April. So, we can find this by dividing the number of clips she sold in April by 2.  48 clips / 2 = 24 clips  Therefore, Natalia sold 24 clips in May.\",\n",
       " \"Now, let's calculate how many clips she sold altogether in April and May. We can find this by adding the number of clips she sold in April and the number of clips she sold in May.  48 clips + 24 clips = 72 clips\",\n",
       " 'Therefore, Natalia sold a total of 72 clips in April and May.']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gsm_df['CoT Sentences'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Prompt</th>\n",
       "      <th>CoT Response</th>\n",
       "      <th>Answer</th>\n",
       "      <th>CoT Sentences</th>\n",
       "      <th>CoT Length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>James creates a media empire.  He creates a mo...</td>\n",
       "      <td>First, let's calculate the total cost of creat...</td>\n",
       "      <td>He sold each DVD for 6*2.5=$&lt;&lt;6*2.5=15&gt;&gt;15\\nSo...</td>\n",
       "      <td>[James creates a media empire.  He creates a m...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0                                             Prompt  \\\n",
       "15          15  James creates a media empire.  He creates a mo...   \n",
       "\n",
       "                                         CoT Response  \\\n",
       "15  First, let's calculate the total cost of creat...   \n",
       "\n",
       "                                               Answer  \\\n",
       "15  He sold each DVD for 6*2.5=$<<6*2.5=15>>15\\nSo...   \n",
       "\n",
       "                                        CoT Sentences  CoT Length  \n",
       "15  [James creates a media empire.  He creates a m...           9  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gsm_df.loc[gsm_df['CoT Length'] == 9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['James creates a media empire.  He creates a movie for $2000.  Each DVD cost $6 to make.  He sells it for 2.5 times that much.  He sells 500 movies a day for 5 days a week.  How much profit does he make in 20 weeks?',\n",
       " \"First, let's calculate the total cost of creating the movie. James creates a movie for $2000.\",\n",
       " \"Next, let's calculate the cost of making each DVD. Each DVD costs $6 to make.\",\n",
       " \"Then, let's calculate the selling price of each DVD. James sells each DVD for 2.5 times the production cost, which is $6 * 2.5 = $<<6*2.5=15>>15.\",\n",
       " \"Now, let's calculate James' profit per DVD. The profit per DVD is the selling price minus the production cost, which is $15 - $6 = $<<15-6=9>>9.\",\n",
       " \"Next, let's calculate James' profit per day. He sells 500 movies a day, so his profit per day is 500 * $9 = $<<500*9=4500>>4500.\",\n",
       " \"Now, let's calculate James' profit per week. He sells movies for 5 days a week, so his profit per week is 5 * $4500 = $<<5*4500=22500>>22500.\",\n",
       " \"Finally, let's calculate James' profit per 20 weeks. His profit per 20 weeks is 20 * $22500 = $<<20*22500=450000>>450000.\",\n",
       " 'Therefore, James makes a profit of $450000 in 20 weeks.']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_df.iloc[15]['QnA_Steps']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_metrics = {}\n",
    "\n",
    "columns_to_average = ['cosine_similarity', 'euclidean_distance', 'manhattan_distance', 'chebyshev_distance', 'euclidean_distance_normalized',\n",
    "                      'random_cosine_similarity', 'random_euclidean_distance', 'random_manhattan_distance', \n",
    "                      'random_chebyshev_distance', 'random_euclidean_distance_normalized']\n",
    "\n",
    "for col in columns_to_average:\n",
    "    all_values = sum(metrics_df[col].tolist(), [])\n",
    "    average_metrics[col] = np.mean(all_values)\n",
    "\n",
    "average_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_value_counts = gsm_df['CoT Length'].value_counts().sort_index()\n",
    "print(sorted_value_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# metric = 'cosine_similarity'\n",
    "metric = 'euclidean_distance'\n",
    "# metric = 'manhattan_distance'\n",
    "# metric = 'chebyshev_distance'\n",
    "# metric = 'euclidean_distance_normalized'\n",
    "\n",
    "length = max(gsm_df['CoT Length'])\n",
    "\n",
    "# Initialize arrays to store sum and count for each index (up to 20)\n",
    "sum_sequential = np.zeros(length)\n",
    "count_sequential = np.zeros(length)\n",
    "sum_random = np.zeros(length)\n",
    "count_random = np.zeros(length)\n",
    "\n",
    "# Iterate through each row to accumulate sums and counts\n",
    "for index, row in metrics_df.iterrows():\n",
    "    # Sequential metrics\n",
    "    for i, value in enumerate(row[metric][:length]):\n",
    "        if not np.isnan(value):\n",
    "            sum_sequential[i] += value\n",
    "            count_sequential[i] += 1\n",
    "    \n",
    "    # Random metrics\n",
    "    for i, value in enumerate(row['random_' + metric][:length]):\n",
    "        if not np.isnan(value):\n",
    "            sum_random[i] += value\n",
    "            count_random[i] += 1\n",
    "\n",
    "# Calculate averages, avoiding division by zero\n",
    "avg_sequential = [sum_sequential[i] / count_sequential[i] if count_sequential[i] != 0 else 0 for i in range(length)]\n",
    "avg_random = [sum_random[i] / count_random[i] if count_random[i] != 0 else 0 for i in range(length)]\n",
    "\n",
    "# Generate bar graph\n",
    "indices = np.arange(length)\n",
    "bar_width = 0.35\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "bar1 = ax.bar(indices - bar_width/2, avg_sequential, bar_width, label='Sequential')\n",
    "bar2 = ax.bar(indices + bar_width/2, avg_random, bar_width, label='Random')\n",
    "\n",
    "ax.set_xlabel('Index')\n",
    "ax.set_ylabel(f'Average {metric.capitalize()}')\n",
    "ax.set_title(f'Average {metric.capitalize()} by Index for Sequential and Random Metrics')\n",
    "ax.set_xticks(indices)\n",
    "ax.set_xticklabels([str(i) for i in range(length)])\n",
    "ax.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# metric = 'cosine_similarity'\n",
    "metric = 'euclidean_distance'\n",
    "# metric = 'manhattan_distance'\n",
    "# metric = 'chebyshev_distance'\n",
    "# metric = 'euclidean_distance_normalized'\n",
    "\n",
    "# Initialize lists to store normalized indices and corresponding metric values\n",
    "sequential_normalized_indices = []\n",
    "sequential_metric_values = []\n",
    "random_normalized_indices = []\n",
    "random_metric_values = []\n",
    "\n",
    "# Iterate through each row to accumulate data points\n",
    "for index, row in metrics_df.iterrows():\n",
    "    trace_length = len(row['QnA_Steps']) - 1  # Exclude the question \n",
    "\n",
    "    # Sequential metrics\n",
    "    for i, value in enumerate(row[metric][:trace_length]):\n",
    "        if not np.isnan(value):\n",
    "            normalized_index = i / (trace_length)\n",
    "            sequential_normalized_indices.append(normalized_index)\n",
    "            sequential_metric_values.append(value)\n",
    "\n",
    "    # Random metrics\n",
    "    for i, value in enumerate(row['random_' + metric][:trace_length]):\n",
    "        if not np.isnan(value):\n",
    "            normalized_index = i / (trace_length)\n",
    "            random_normalized_indices.append(normalized_index)\n",
    "            random_metric_values.append(value)\n",
    "\n",
    "plt.scatter(sequential_normalized_indices, sequential_metric_values, color='blue', label='Sequential')\n",
    "plt.scatter(random_normalized_indices, random_metric_values, color='red', label='Random')\n",
    "\n",
    "plt.xlabel('Normalized Index')\n",
    "plt.ylabel(f'{metric.capitalize()}')\n",
    "plt.title(f'{metric.capitalize()} for Sequential and Random Metrics')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert lists to DataFrame for easier manipulation\n",
    "data_sequential = pd.DataFrame({\n",
    "    'normalized_index': sequential_normalized_indices,\n",
    "    'metric_value': sequential_metric_values\n",
    "})\n",
    "data_random = pd.DataFrame({\n",
    "    'normalized_index': random_normalized_indices,\n",
    "    'metric_value': random_metric_values\n",
    "})\n",
    "\n",
    "# Calculate the average metric value for each normalized index\n",
    "avg_sequential = data_sequential.groupby('normalized_index').mean().reset_index()\n",
    "avg_random = data_random.groupby('normalized_index').mean().reset_index()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "plt.scatter(data_sequential['normalized_index'], data_sequential['metric_value'], alpha=0.1, color='blue')\n",
    "plt.scatter(data_random['normalized_index'], data_random['metric_value'], alpha=0.1, color='red')\n",
    "\n",
    "# Plot the trend line\n",
    "plt.plot(avg_sequential['normalized_index'], avg_sequential['metric_value'], color='blue', label='Sequential Average')\n",
    "plt.plot(avg_random['normalized_index'], avg_random['metric_value'], color='red', label='Random Average')\n",
    "\n",
    "plt.xlabel('Normalized Index')\n",
    "plt.ylabel(f'Average {metric.capitalize()}')\n",
    "plt.title(f'{metric.capitalize()} for Sequential and Random Metrics')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "euclidean_ranges = metrics_df['euclidean_distance'].apply(lambda x: max(x) - min(x))\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(euclidean_ranges, bins=30, color='skyblue', edgecolor='black')\n",
    "plt.title('Histogram of Euclidean Distance Ranges')\n",
    "plt.xlabel('Range of Euclidean Distance')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "euclidean_ranges.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the reasoning traces with a Euclidean distance range of zero\n",
    "traces_with_zero_range = metrics_df[metrics_df['euclidean_distance'].apply(lambda x: max(x) - min(x)) == 0]\n",
    "\n",
    "# Inspect the traces and their corresponding original text\n",
    "traces_with_zero_range_info = traces_with_zero_range[['euclidean_distance', 'Original_Text', 'QnA_Steps']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traces_with_zero_range_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gsm_df.iloc[28]['CoT Sentences']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gsm_df.at[28, 'CoT Sentences'] = ['There are 5 houses on a street, and each of the first four houses has 3 gnomes in the garden. If there are a total of 20 gnomes on the street, how many gnomes does the fifth house have?',\n",
    " \"1. Let's start by figuring out how many gnomes are in the first four houses combined. Each of the first four houses has 3 gnomes, so the total number of gnomes in those houses is 3 * 4 = 12.\",\n",
    " \"2. We know that the total number of gnomes on the street is 20. Since we already accounted for 12 gnomes in the first four houses, that means the fifth house must have the remaining gnomes. So the fifth house must have 20 - 12 = 8 gnomes.\",\n",
    " \"Therefore, the fifth house has 8 gnomes in its garden.\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(gsm_df.iloc[28]['CoT Sentences'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "reasoning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
