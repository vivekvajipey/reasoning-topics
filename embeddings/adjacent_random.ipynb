{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import umap\n",
    "from sklearn.manifold import TSNE\n",
    "from scipy.spatial import distance\n",
    "import warnings\n",
    "import re\n",
    "import random\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import embedding_plotting\n",
    "import trace_utils\n",
    "importlib.reload(embedding_plotting)\n",
    "importlib.reload(trace_utils)\n",
    "\n",
    "\n",
    "from embedding_plotting import DimensionalViz\n",
    "from embedding_plotting import cot_step_print\n",
    "from trace_utils import split_cot\n",
    "from trace_utils import compute_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gsm_df = pd.read_csv('data/cot_data_50_start_sentences_autosplit.csv')\n",
    "gsm_df['CoT Sentences'] = gsm_df['CoT Sentences'].apply(split_cot)\n",
    "\n",
    "# gsm_df = pd.read_csv('data/cot_data_50_start_sentences_sentsplit.csv')\n",
    "# gsm_df['CoT Sentences'] = gsm_df['CoT Sentences'].apply(ast.literal_eval)\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gsm_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gsm_df['CoT Length'] = gsm_df['CoT Sentences'].apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "def plot_cot_step_metrics(cot_collection):\n",
    "    \"\"\"\n",
    "    Plots metric sequence for all inputted sentences\n",
    "    \"\"\"\n",
    "    embeddings_collection = []\n",
    "    metrics_adjacent_collection = []\n",
    "    metrics_random_collection = []\n",
    "    for trace in cot_collection:\n",
    "        embeddings = [model.encode(step) for step in trace]\n",
    "        embeddings_collection.append(embeddings)\n",
    "        metrics_adjacent = []\n",
    "        metrics_random = []\n",
    "        for i in range(len(embeddings) - 1):\n",
    "            emb1 = embeddings[i]\n",
    "            emb2 = embeddings[i + 1]\n",
    "\n",
    "            # Compute metric for adjacent steps\n",
    "            metric_adjacent = distance.euclidean(emb1, emb2)\n",
    "            metrics_adjacent.append(metric_adjacent)\n",
    "\n",
    "            # Compute metric for random steps\n",
    "            other_embeddings = embeddings[:i] + embeddings[i+2:]  # Exclude the current and next step's embeddings\n",
    "            emb_random = random.choice(other_embeddings)\n",
    "            metric_random = distance.euclidean(emb1, emb_random)\n",
    "            metrics_random.append(metric_random)\n",
    "\n",
    "        metrics_adjacent_collection.append(metrics_adjacent)\n",
    "        metrics_random_collection.append(metrics_random)\n",
    "\n",
    "    # Plotting\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    colors = ['b', 'g', 'r', 'c', 'm', 'y', 'k']  # List of colors for the traces\n",
    "    for i, (metrics_adjacent, metrics_random) in enumerate(zip(metrics_adjacent_collection, metrics_random_collection)):\n",
    "        indices = list(range(len(metrics_adjacent)))\n",
    "        color = colors[i % len(colors)]  # Select a color from the list\n",
    "        plt.plot(indices, metrics_adjacent, label=f'Trace {i+1} (Adjacent)', color=color)\n",
    "        plt.plot(indices, metrics_random, label=f'Trace {i+1} (Random)', linestyle='dashed', color=color)\n",
    "\n",
    "    plt.xlabel('Step Index')\n",
    "    plt.ylabel('Euclidean Distance')\n",
    "    plt.title('Euclidean Distance between Successive and Random Embeddings for Each Trace')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cot_collection_1 = []\n",
    "cot_collection_1.append(['Betty sold Apples to 48 of her friends in April, and then she sold half as many Apples in May. How many Apples did Betty sell altogether in April and May?',\n",
    " \"First, let's calculate how many Apples Betty sold in May. We know that she sold half as many Apples in May as she did in April. So, we can find this by dividing the number of Apples she sold in April by 2. 48 Apples / 2 = 24 Apples Therefore, Betty sold 24 Apples in May.\",\n",
    " \"Now, let's calculate how many Apples she sold altogether in April and May. We can find this by adding the number of Apples she sold in April and the number of Apples she sold in May. 48 Apples + 24 Apples = 72 Apples\",\n",
    " 'Therefore, Betty sold a total of 72 Apples in April and May.'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_cot_step_metrics(cot_collection_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_cot(cot_collection[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(sampled_df['CoT Sentences'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_df['CoT Sentences'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_df = gsm_df.sample(3)\n",
    "cot_collection = []\n",
    "for i, trace in enumerate(sampled_df['CoT Sentences'].tolist()):\n",
    "    first_three_words = \" \".join(sampled_df['Prompt'].iloc[i].split()[:3])\n",
    "    print(\"Prompts:\")\n",
    "    print(f\"Trace {i + 1}: {first_three_words}...\")\n",
    "    # cot_collection.append(split_cot(trace))\n",
    "    cot_collection.append(trace)\n",
    "plot_cot_step_metrics(cot_collection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gsm_df[gsm_df['Prompt'].str.startswith('A deep-sea monster')].index[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gsm_df.iloc[10]['Answer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, step in enumerate(gsm_df.iloc[10]['CoT Sentences']):\n",
    "    print(f\"Step {i}: \", step)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aggregating Metrics Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_list = []\n",
    "cot_steps_list = []\n",
    "original_text_list = []\n",
    "metrics_list = []\n",
    "\n",
    "for i in range(len(gsm_df)):\n",
    "    question = gsm_df['Prompt'][i]\n",
    "    cot_reasoning = gsm_df['CoT Sentences'][i]\n",
    "    cot_reasoning.insert(0, question)\n",
    "    cot_steps_list.append(cot_reasoning)\n",
    "    cot_embeddings = model.encode(cot_reasoning)\n",
    "    \n",
    "    embeddings_list.append(cot_embeddings)\n",
    "    original_text_list.append(cot_reasoning)\n",
    "    metrics_list.append(compute_metrics(cot_embeddings))\n",
    "\n",
    "# Convert lists to DataFrame\n",
    "metrics_df = pd.DataFrame(metrics_list)\n",
    "metrics_df['Original_Text'] = original_text_list\n",
    "metrics_df['QnA_Steps'] = cot_steps_list\n",
    "metrics_df['Embeddings'] = embeddings_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_metrics = {}\n",
    "\n",
    "columns_to_average = ['cosine_similarity', 'euclidean_distance', 'manhattan_distance', 'chebyshev_distance', 'euclidean_distance_normalized',\n",
    "                      'random_cosine_similarity', 'random_euclidean_distance', 'random_manhattan_distance', \n",
    "                      'random_chebyshev_distance', 'random_euclidean_distance_normalized']\n",
    "\n",
    "for col in columns_to_average:\n",
    "    all_values = sum(metrics_df[col].tolist(), [])\n",
    "    average_metrics[col] = np.mean(all_values)\n",
    "\n",
    "average_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_value_counts = gsm_df['CoT Length'].value_counts().sort_index()\n",
    "print(sorted_value_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# metric = 'cosine_similarity'\n",
    "metric = 'euclidean_distance'\n",
    "# metric = 'manhattan_distance'\n",
    "# metric = 'chebyshev_distance'\n",
    "# metric = 'euclidean_distance_normalized'\n",
    "\n",
    "length = max(gsm_df['CoT Length'])\n",
    "\n",
    "# Initialize arrays to store sum and count for each index (up to 20)\n",
    "sum_sequential = np.zeros(length)\n",
    "count_sequential = np.zeros(length)\n",
    "sum_random = np.zeros(length)\n",
    "count_random = np.zeros(length)\n",
    "\n",
    "# Iterate through each row to accumulate sums and counts\n",
    "for index, row in metrics_df.iterrows():\n",
    "    # Sequential metrics\n",
    "    for i, value in enumerate(row[metric][:length]):\n",
    "        if not np.isnan(value):\n",
    "            sum_sequential[i] += value\n",
    "            count_sequential[i] += 1\n",
    "    \n",
    "    # Random metrics\n",
    "    for i, value in enumerate(row['random_' + metric][:length]):\n",
    "        if not np.isnan(value):\n",
    "            sum_random[i] += value\n",
    "            count_random[i] += 1\n",
    "\n",
    "# Calculate averages, avoiding division by zero\n",
    "avg_sequential = [sum_sequential[i] / count_sequential[i] if count_sequential[i] != 0 else 0 for i in range(length)]\n",
    "avg_random = [sum_random[i] / count_random[i] if count_random[i] != 0 else 0 for i in range(length)]\n",
    "\n",
    "# Generate bar graph\n",
    "indices = np.arange(length)\n",
    "bar_width = 0.35\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "bar1 = ax.bar(indices - bar_width/2, avg_sequential, bar_width, label='Sequential')\n",
    "bar2 = ax.bar(indices + bar_width/2, avg_random, bar_width, label='Random')\n",
    "\n",
    "ax.set_xlabel('Index')\n",
    "ax.set_ylabel(f'Average {metric.capitalize()}')\n",
    "ax.set_title(f'Average {metric.capitalize()} by Index for Sequential and Random Metrics')\n",
    "ax.set_xticks(indices)\n",
    "ax.set_xticklabels([str(i) for i in range(length)])\n",
    "ax.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# metric = 'cosine_similarity'\n",
    "metric = 'euclidean_distance'\n",
    "# metric = 'manhattan_distance'\n",
    "# metric = 'chebyshev_distance'\n",
    "# metric = 'euclidean_distance_normalized'\n",
    "\n",
    "# Initialize lists to store normalized indices and corresponding metric values\n",
    "sequential_normalized_indices = []\n",
    "sequential_metric_values = []\n",
    "random_normalized_indices = []\n",
    "random_metric_values = []\n",
    "\n",
    "# Iterate through each row to accumulate data points\n",
    "for index, row in metrics_df.iterrows():\n",
    "    trace_length = len(row['QnA_Steps']) - 1  # Exclude the question \n",
    "\n",
    "    # Sequential metrics\n",
    "    for i, value in enumerate(row[metric][:trace_length]):\n",
    "        if not np.isnan(value):\n",
    "            normalized_index = i / (trace_length)\n",
    "            sequential_normalized_indices.append(normalized_index)\n",
    "            sequential_metric_values.append(value)\n",
    "\n",
    "    # Random metrics\n",
    "    for i, value in enumerate(row['random_' + metric][:trace_length]):\n",
    "        if not np.isnan(value):\n",
    "            normalized_index = i / (trace_length)\n",
    "            random_normalized_indices.append(normalized_index)\n",
    "            random_metric_values.append(value)\n",
    "\n",
    "plt.scatter(sequential_normalized_indices, sequential_metric_values, color='blue', label='Sequential')\n",
    "plt.scatter(random_normalized_indices, random_metric_values, color='red', label='Random')\n",
    "\n",
    "plt.xlabel('Normalized Index')\n",
    "plt.ylabel(f'{metric.capitalize()}')\n",
    "plt.title(f'{metric.capitalize()} for Sequential and Random Metrics')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert lists to DataFrame for easier manipulation\n",
    "data_sequential = pd.DataFrame({\n",
    "    'normalized_index': sequential_normalized_indices,\n",
    "    'metric_value': sequential_metric_values\n",
    "})\n",
    "data_random = pd.DataFrame({\n",
    "    'normalized_index': random_normalized_indices,\n",
    "    'metric_value': random_metric_values\n",
    "})\n",
    "\n",
    "# Calculate the average metric value for each normalized index\n",
    "avg_sequential = data_sequential.groupby('normalized_index').mean().reset_index()\n",
    "avg_random = data_random.groupby('normalized_index').mean().reset_index()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "plt.scatter(data_sequential['normalized_index'], data_sequential['metric_value'], alpha=0.1, color='blue')\n",
    "plt.scatter(data_random['normalized_index'], data_random['metric_value'], alpha=0.1, color='red')\n",
    "\n",
    "# Plot the trend line\n",
    "plt.plot(avg_sequential['normalized_index'], avg_sequential['metric_value'], color='blue', label='Sequential Average')\n",
    "plt.plot(avg_random['normalized_index'], avg_random['metric_value'], color='red', label='Random Average')\n",
    "\n",
    "plt.xlabel('Normalized Index')\n",
    "plt.ylabel(f'Average {metric.capitalize()}')\n",
    "plt.title(f'{metric.capitalize()} for Sequential and Random Metrics')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_metrics(metrics):\n",
    "    min_val = min(metrics)\n",
    "    max_val = max(metrics)\n",
    "    range_val = max_val - min_val\n",
    "    if range_val > 0:\n",
    "        normalized_metrics = [(m - min_val) / range_val for m in metrics]\n",
    "    else:\n",
    "        normalized_metrics = [0 for _ in metrics]\n",
    "    return normalized_metrics\n",
    "\n",
    "metrics_df['euclidean_distance_normalized'] = metrics_df['euclidean_distance'].apply(normalize_metrics)\n",
    "metrics_df['random_euclidean_distance_normalized'] = metrics_df['random_' + 'euclidean_distance'].apply(normalize_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "euclidean_ranges = metrics_df['euclidean_distance'].apply(lambda x: max(x) - min(x))\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(euclidean_ranges, bins=30, color='skyblue', edgecolor='black')\n",
    "plt.title('Histogram of Euclidean Distance Ranges')\n",
    "plt.xlabel('Range of Euclidean Distance')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "euclidean_ranges.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the reasoning traces with a Euclidean distance range of zero\n",
    "traces_with_zero_range = metrics_df[metrics_df['euclidean_distance'].apply(lambda x: max(x) - min(x)) == 0]\n",
    "\n",
    "# Inspect the traces and their corresponding original text\n",
    "traces_with_zero_range_info = traces_with_zero_range[['euclidean_distance', 'Original_Text', 'QnA_Steps']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traces_with_zero_range_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gsm_df.iloc[28]['CoT Sentences']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gsm_df.at[28, 'CoT Sentences'] = ['There are 5 houses on a street, and each of the first four houses has 3 gnomes in the garden. If there are a total of 20 gnomes on the street, how many gnomes does the fifth house have?',\n",
    " \"1. Let's start by figuring out how many gnomes are in the first four houses combined. Each of the first four houses has 3 gnomes, so the total number of gnomes in those houses is 3 * 4 = 12.\",\n",
    " \"2. We know that the total number of gnomes on the street is 20. Since we already accounted for 12 gnomes in the first four houses, that means the fifth house must have the remaining gnomes. So the fifth house must have 20 - 12 = 8 gnomes.\",\n",
    " \"Therefore, the fifth house has 8 gnomes in its garden.\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(gsm_df.iloc[28]['CoT Sentences'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "reasoning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
